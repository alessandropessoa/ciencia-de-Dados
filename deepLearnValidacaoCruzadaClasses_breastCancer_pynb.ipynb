{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Usando a biblioteca  skorch que é um wrapper para pytorch e sklearn\n",
        "que realiza validação cruzada com sklearn\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "jIlOqprJRsGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install skorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v0iD4_SYIUb",
        "outputId": "f6115bcd-4437-4ac0-d40b-757457700d1c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: skorch in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.10.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (4.65.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from skorch import NeuralNetBinaryClassifier\n",
        "from sklearn.model_selection import cross_val_score # validação cruzada\n",
        "import torch\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "etND9l2_RW_H"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer"
      ],
      "metadata": {
        "id": "RjZQIZMFVJRG"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(123)\n",
        "torch.manual_seed(123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muS8mj08SvFM",
        "outputId": "0f1151b4-d2c2-49cc-ee5e-d473141b5ea2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7b12b01f8a70>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_breast_cancer()"
      ],
      "metadata": {
        "id": "cYdMu9GhTnkF"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ds['DESCR'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRNgMvOjWt-3",
        "outputId": "45303617-a0cf-48c6-e06e-dfd3b9699409"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _breast_cancer_dataset:\n",
            "\n",
            "Breast cancer wisconsin (diagnostic) dataset\n",
            "--------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 569\n",
            "\n",
            "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
            "\n",
            "    :Attribute Information:\n",
            "        - radius (mean of distances from center to points on the perimeter)\n",
            "        - texture (standard deviation of gray-scale values)\n",
            "        - perimeter\n",
            "        - area\n",
            "        - smoothness (local variation in radius lengths)\n",
            "        - compactness (perimeter^2 / area - 1.0)\n",
            "        - concavity (severity of concave portions of the contour)\n",
            "        - concave points (number of concave portions of the contour)\n",
            "        - symmetry\n",
            "        - fractal dimension (\"coastline approximation\" - 1)\n",
            "\n",
            "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
            "        worst/largest values) of these features were computed for each image,\n",
            "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
            "        10 is Radius SE, field 20 is Worst Radius.\n",
            "\n",
            "        - class:\n",
            "                - WDBC-Malignant\n",
            "                - WDBC-Benign\n",
            "\n",
            "    :Summary Statistics:\n",
            "\n",
            "    ===================================== ====== ======\n",
            "                                           Min    Max\n",
            "    ===================================== ====== ======\n",
            "    radius (mean):                        6.981  28.11\n",
            "    texture (mean):                       9.71   39.28\n",
            "    perimeter (mean):                     43.79  188.5\n",
            "    area (mean):                          143.5  2501.0\n",
            "    smoothness (mean):                    0.053  0.163\n",
            "    compactness (mean):                   0.019  0.345\n",
            "    concavity (mean):                     0.0    0.427\n",
            "    concave points (mean):                0.0    0.201\n",
            "    symmetry (mean):                      0.106  0.304\n",
            "    fractal dimension (mean):             0.05   0.097\n",
            "    radius (standard error):              0.112  2.873\n",
            "    texture (standard error):             0.36   4.885\n",
            "    perimeter (standard error):           0.757  21.98\n",
            "    area (standard error):                6.802  542.2\n",
            "    smoothness (standard error):          0.002  0.031\n",
            "    compactness (standard error):         0.002  0.135\n",
            "    concavity (standard error):           0.0    0.396\n",
            "    concave points (standard error):      0.0    0.053\n",
            "    symmetry (standard error):            0.008  0.079\n",
            "    fractal dimension (standard error):   0.001  0.03\n",
            "    radius (worst):                       7.93   36.04\n",
            "    texture (worst):                      12.02  49.54\n",
            "    perimeter (worst):                    50.41  251.2\n",
            "    area (worst):                         185.2  4254.0\n",
            "    smoothness (worst):                   0.071  0.223\n",
            "    compactness (worst):                  0.027  1.058\n",
            "    concavity (worst):                    0.0    1.252\n",
            "    concave points (worst):               0.0    0.291\n",
            "    symmetry (worst):                     0.156  0.664\n",
            "    fractal dimension (worst):            0.055  0.208\n",
            "    ===================================== ====== ======\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
            "\n",
            "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
            "\n",
            "    :Donor: Nick Street\n",
            "\n",
            "    :Date: November, 1995\n",
            "\n",
            "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
            "https://goo.gl/U2Uwz2\n",
            "\n",
            "Features are computed from a digitized image of a fine needle\n",
            "aspirate (FNA) of a breast mass.  They describe\n",
            "characteristics of the cell nuclei present in the image.\n",
            "\n",
            "Separating plane described above was obtained using\n",
            "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
            "Construction Via Linear Programming.\" Proceedings of the 4th\n",
            "Midwest Artificial Intelligence and Cognitive Science Society,\n",
            "pp. 97-101, 1992], a classification method which uses linear\n",
            "programming to construct a decision tree.  Relevant features\n",
            "were selected using an exhaustive search in the space of 1-4\n",
            "features and 1-3 separating planes.\n",
            "\n",
            "The actual linear program used to obtain the separating plane\n",
            "in the 3-dimensional space is that described in:\n",
            "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
            "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
            "Optimization Methods and Software 1, 1992, 23-34].\n",
            "\n",
            "This database is also available through the UW CS ftp server:\n",
            "\n",
            "ftp ftp.cs.wisc.edu\n",
            "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
            "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
            "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
            "     San Jose, CA, 1993.\n",
            "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
            "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
            "     July-August 1995.\n",
            "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
            "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
            "     163-171.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dsPreditores  = ds['data']\n",
        "dsAlvo        = ds['target']"
      ],
      "metadata": {
        "id": "emAp-dWEVhUZ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dsPreditores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTj8XXT4WBdF",
        "outputId": "35eda5c9-81a8-4134-b074-1cd377cc68ad"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dsAlvo.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6TuntrUWedi",
        "outputId": "c9877957-73a5-40eb-ff14-af2d9c2fb41f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569,)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds['feature_names']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGrE0llsWirA",
        "outputId": "e0aa79a9-5f73-49a9-fd70-36831245f590"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "       'smoothness error', 'compactness error', 'concavity error',\n",
              "       'concave points error', 'symmetry error',\n",
              "       'fractal dimension error', 'worst radius', 'worst texture',\n",
              "       'worst perimeter', 'worst area', 'worst smoothness',\n",
              "       'worst compactness', 'worst concavity', 'worst concave points',\n",
              "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_preditores = pd.DataFrame(dsPreditores)"
      ],
      "metadata": {
        "id": "yZQm1DgjW6bV"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_alvo = pd.DataFrame(dsAlvo)"
      ],
      "metadata": {
        "id": "EcTfllJ7XIez"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=df_alvo[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "gig8fSIEXOPc",
        "outputId": "a5509b53-7d55-407e-e1e5-3152d0446ba6"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='0', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dsPreditores.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYhr7Eegbb0B",
        "outputId": "3008561b-ebe0-479d-8818-46d6e2014aa4"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dsPreditores = np.array(dsPreditores,dtype='float32')\n",
        "dsAlvo = np.array(dsAlvo,dtype='float32')"
      ],
      "metadata": {
        "id": "d7C8Lxh2cXpT"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dsAlvo.dtype,dsPreditores.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R88lL_yac1ft",
        "outputId": "b6a69a9c-5c8f-4922-e96d-3632284f41fc"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('float32'), dtype('float32'))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como o classsificador tem um objetivo de classificar binariamente,0 sem cancer e 1com cancer, podemos utilizar apenas um neuronio na saida e como temos 30 variaveis explanatorias (independentes ou preditoras), precisamos de 16 neuronios, pois usamos o calculo entradas+saida/2 -> (30+1)/2 = 15.5=16,    "
      ],
      "metadata": {
        "id": "WcHz3ttwkW9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class classidicadorTorch(nn.Module):\n",
        "  def __init__(self):\n",
        "    \"\"\"\n",
        "      a estrutura dessa rede neural é 30 -> 16 ->16->1\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "\n",
        "    # primeira camada densa com 30 entradas ligado a 16 neuronios\n",
        "    self.camada0 = nn.Linear(30,16)\n",
        "    torch.nn.init.uniform_(self.camada0.weight) # inicia os pesos com uma distribuição uniforme\n",
        "    self.camadaAtivacao0 = nn.ReLU()\n",
        "\n",
        "    #segunda camada densa, cada camada oculta com 16 neuronios.\n",
        "    self.camada1 = nn.Linear(16,16)\n",
        "    torch.nn.init.uniform_(self.camada1.weight)\n",
        "    self.camadaAtivacao1 = nn.ReLU()\n",
        "\n",
        "    #camda de saida densa, camada oculta para camada de saida 16->1\n",
        "    self.camadaSaida = nn.Linear(16,1)\n",
        "    torch.nn.init.uniform_(self.camadaSaida.weight)\n",
        "    # self.camadaAtivacaoSaida = nn.Sigmoid() #nesta versao nao precisa de sigmoid na saida, ele ja faz\n",
        "\n",
        "  def forward(self,valoresEntrada):\n",
        "    \"\"\"\n",
        "      Propagação dos valores dentro da rede neural\n",
        "    \"\"\"\n",
        "    elemento = self.camada0(valoresEntrada)\n",
        "    elemento = self.camadaAtivacao0(elemento)\n",
        "\n",
        "    elemento = self.camada1(elemento)\n",
        "    elemento = self.camadaAtivacao1(elemento)\n",
        "\n",
        "    elemento = self.camadaSaida(elemento)\n",
        "    # elemento = self.camadaAtivacaoSaida(elemento) #nesta versao nao precisa de sigmoid na saida, ele ja faz\n",
        "    return elemento\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Prl_kCgcc7r2"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# o parametro train_split não permite que seja separado o dataset em treino e teste pois\n",
        "# será feito posteriomente pelo sklearn com validação cruzada, ou seja por padrão\n",
        "# é separa em treino e teste\n",
        "\n",
        "classificador_sklearn = NeuralNetBinaryClassifier(module = classidicadorTorch,\\\n",
        "                                                  criterion = torch.nn.BCEWithLogitsLoss,\\\n",
        "                                                  optimizer = torch.optim.Adam,\\\n",
        "                                                  lr = 0.001 ,\\\n",
        "                                                  optimizer__weight_decay = 0.0001,\\\n",
        "                                                  max_epochs = 100,\\\n",
        "                                                  batch_size = 10,\\\n",
        "                                                  train_split = False,\\\n",
        "                                                  )"
      ],
      "metadata": {
        "id": "i8AieUfufuGq"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "após construção do classsificador podemos realizar a validação cruzada, para avaliar o nosso modelo e será utilizado a acuracia como metrica de avaliação poderia ser utilizado o f1-score, recall, precisao, já o valor de k-fold (cv) é 10"
      ],
      "metadata": {
        "id": "PsEsKEstsbBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultados =cross_val_score(classificador_sklearn,dsPreditores, dsAlvo, cv=10, scoring='accuracy')"
      ],
      "metadata": {
        "id": "QByNs7mGsRaN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f387285-e4b8-4a8b-8ff9-43cd5bbabeb9"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m35678.5899\u001b[0m  0.0963\n",
            "      2    \u001b[36m28317.4645\u001b[0m  0.0898\n",
            "      3    \u001b[36m22180.3231\u001b[0m  0.0830\n",
            "      4    \u001b[36m17233.9144\u001b[0m  0.1739\n",
            "      5    \u001b[36m13264.1854\u001b[0m  0.2524\n",
            "      6    \u001b[36m10080.1095\u001b[0m  0.1534\n",
            "      7     \u001b[36m7480.4298\u001b[0m  0.0981\n",
            "      8     \u001b[36m5340.0735\u001b[0m  0.0965\n",
            "      9     \u001b[36m3559.7626\u001b[0m  0.1129\n",
            "     10     \u001b[36m2004.6531\u001b[0m  0.1080\n",
            "     11      \u001b[36m599.5127\u001b[0m  0.0804\n",
            "     12       \u001b[36m35.1469\u001b[0m  0.1147\n",
            "     13       \u001b[36m32.2575\u001b[0m  0.1504\n",
            "     14       \u001b[36m26.4348\u001b[0m  0.1463\n",
            "     15       \u001b[36m21.1275\u001b[0m  0.1049\n",
            "     16       \u001b[36m18.5674\u001b[0m  0.0913\n",
            "     17       \u001b[36m16.7161\u001b[0m  0.0963\n",
            "     18       \u001b[36m15.3442\u001b[0m  0.0932\n",
            "     19       \u001b[36m14.6295\u001b[0m  0.0861\n",
            "     20       \u001b[36m14.4738\u001b[0m  0.0888\n",
            "     21       \u001b[36m13.4063\u001b[0m  0.0809\n",
            "     22       \u001b[36m12.8779\u001b[0m  0.0965\n",
            "     23       \u001b[36m11.4488\u001b[0m  0.0934\n",
            "     24       12.1469  0.0887\n",
            "     25       \u001b[36m10.9732\u001b[0m  0.0818\n",
            "     26        \u001b[36m9.7949\u001b[0m  0.0865\n",
            "     27        \u001b[36m8.7182\u001b[0m  0.0848\n",
            "     28        \u001b[36m8.5717\u001b[0m  0.0828\n",
            "     29        \u001b[36m8.3729\u001b[0m  0.2638\n",
            "     30        \u001b[36m8.2927\u001b[0m  0.1404\n",
            "     31        \u001b[36m8.2456\u001b[0m  0.1357\n",
            "     32        \u001b[36m8.1769\u001b[0m  0.1794\n",
            "     33        \u001b[36m8.0032\u001b[0m  0.1250\n",
            "     34        \u001b[36m7.8706\u001b[0m  0.1662\n",
            "     35        \u001b[36m7.6452\u001b[0m  0.1658\n",
            "     36        \u001b[36m6.8229\u001b[0m  0.1405\n",
            "     37        6.8988  0.1392\n",
            "     38        \u001b[36m6.5303\u001b[0m  0.1482\n",
            "     39        \u001b[36m6.4561\u001b[0m  0.2507\n",
            "     40        \u001b[36m6.3332\u001b[0m  0.1578\n",
            "     41        \u001b[36m6.0654\u001b[0m  0.2033\n",
            "     42        \u001b[36m5.9245\u001b[0m  0.1514\n",
            "     43        \u001b[36m5.8059\u001b[0m  0.1243\n",
            "     44        \u001b[36m5.7104\u001b[0m  0.1883\n",
            "     45        \u001b[36m5.6569\u001b[0m  0.1225\n",
            "     46        \u001b[36m5.5051\u001b[0m  0.1415\n",
            "     47        \u001b[36m5.2173\u001b[0m  0.3677\n",
            "     48        5.3643  0.5791\n",
            "     49        \u001b[36m5.0186\u001b[0m  0.5547\n",
            "     50        \u001b[36m4.9590\u001b[0m  0.5433\n",
            "     51        4.9818  0.4871\n",
            "     52        \u001b[36m4.8986\u001b[0m  0.5178\n",
            "     53        \u001b[36m4.8884\u001b[0m  0.3805\n",
            "     54        \u001b[36m4.8636\u001b[0m  0.4655\n",
            "     55        \u001b[36m4.7722\u001b[0m  0.1563\n",
            "     56        \u001b[36m4.3790\u001b[0m  0.1320\n",
            "     57        \u001b[36m3.9342\u001b[0m  0.2462\n",
            "     58        4.1565  0.3801\n",
            "     59        \u001b[36m3.8252\u001b[0m  0.3387\n",
            "     60        3.9103  0.2481\n",
            "     61        3.9633  0.3582\n",
            "     62        3.9276  0.2158\n",
            "     63        \u001b[36m3.7412\u001b[0m  0.2059\n",
            "     64        3.7628  0.2283\n",
            "     65        \u001b[36m3.6389\u001b[0m  0.2267\n",
            "     66        3.6463  0.2005\n",
            "     67        3.7826  0.1733\n",
            "     68        4.0255  0.1566\n",
            "     69        3.8865  0.1757\n",
            "     70        4.2043  0.1436\n",
            "     71        3.7718  0.2230\n",
            "     72        4.0383  0.1601\n",
            "     73        4.0858  0.1709\n",
            "     74        4.5006  0.1305\n",
            "     75        4.3726  0.2558\n",
            "     76        4.4675  0.1611\n",
            "     77        4.3270  0.1485\n",
            "     78        4.3641  0.2273\n",
            "     79        4.3864  0.2347\n",
            "     80        4.6263  0.2755\n",
            "     81        3.8535  0.1503\n",
            "     82        4.2345  0.2153\n",
            "     83        4.3929  0.3372\n",
            "     84        3.9047  0.1896\n",
            "     85        4.3107  0.1234\n",
            "     86        4.1931  0.2023\n",
            "     87        4.1111  0.2556\n",
            "     88        4.1208  0.1849\n",
            "     89        4.1198  0.3664\n",
            "     90        4.0723  0.3090\n",
            "     91        4.2481  0.2002\n",
            "     92        4.1973  0.1707\n",
            "     93        4.1289  0.1302\n",
            "     94        4.1369  0.2143\n",
            "     95        4.0991  0.3166\n",
            "     96        4.0424  0.1846\n",
            "     97        3.7317  0.2435\n",
            "     98        3.8338  0.4147\n",
            "     99        3.7613  0.2829\n",
            "    100        3.8234  0.4673\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m27392.1170\u001b[0m  0.4868\n",
            "      2    \u001b[36m20965.7713\u001b[0m  0.4064\n",
            "      3    \u001b[36m15587.9504\u001b[0m  0.5084\n",
            "      4    \u001b[36m11206.1215\u001b[0m  0.4595\n",
            "      5     \u001b[36m7663.4778\u001b[0m  0.2100\n",
            "      6     \u001b[36m4710.6632\u001b[0m  0.1628\n",
            "      7     \u001b[36m2119.0210\u001b[0m  0.1887\n",
            "      8      \u001b[36m218.5842\u001b[0m  0.2033\n",
            "      9        \u001b[36m6.2948\u001b[0m  0.1925\n",
            "     10        \u001b[36m1.2083\u001b[0m  0.1296\n",
            "     11        1.3365  0.1993\n",
            "     12        1.4043  0.1933\n",
            "     13        1.6137  0.1475\n",
            "     14        1.6903  0.2547\n",
            "     15        1.6218  0.2949\n",
            "     16        1.7239  0.4073\n",
            "     17        1.2878  0.2047\n",
            "     18        1.3760  0.4646\n",
            "     19        1.2102  0.3275\n",
            "     20        1.6012  0.1451\n",
            "     21        \u001b[36m1.1003\u001b[0m  0.1562\n",
            "     22        \u001b[36m0.8779\u001b[0m  0.3057\n",
            "     23        0.8867  0.2661\n",
            "     24        0.9119  0.1414\n",
            "     25        0.9270  0.1268\n",
            "     26        \u001b[36m0.8568\u001b[0m  0.1935\n",
            "     27        \u001b[36m0.7116\u001b[0m  0.2536\n",
            "     28        2.3705  0.2193\n",
            "     29        1.4876  0.1754\n",
            "     30        0.8447  0.1653\n",
            "     31        1.0846  0.2367\n",
            "     32        \u001b[36m0.6809\u001b[0m  0.3538\n",
            "     33        1.3259  0.5133\n",
            "     34        0.6986  0.4305\n",
            "     35        1.2461  0.2205\n",
            "     36        0.7246  0.0837\n",
            "     37        1.2583  0.0884\n",
            "     38        1.8211  0.0892\n",
            "     39        2.3054  0.0848\n",
            "     40        2.0605  0.0883\n",
            "     41        1.2612  0.0966\n",
            "     42        1.2762  0.0870\n",
            "     43        1.3958  0.0893\n",
            "     44        1.5083  0.0873\n",
            "     45        0.8077  0.0841\n",
            "     46        1.4302  0.0872\n",
            "     47        1.2515  0.0862\n",
            "     48        \u001b[36m0.6392\u001b[0m  0.0890\n",
            "     49        1.4725  0.0935\n",
            "     50        0.6580  0.0833\n",
            "     51        1.5074  0.0879\n",
            "     52        1.2399  0.0940\n",
            "     53        1.9940  0.0887\n",
            "     54        0.8556  0.0878\n",
            "     55        1.6098  0.0946\n",
            "     56        1.2561  0.0801\n",
            "     57        1.4367  0.0800\n",
            "     58        1.0499  0.0871\n",
            "     59        1.6181  0.0819\n",
            "     60        1.0787  0.0816\n",
            "     61        1.4308  0.1114\n",
            "     62        2.0244  0.1395\n",
            "     63        2.7520  0.1419\n",
            "     64        1.4678  0.1245\n",
            "     65        1.8766  0.1187\n",
            "     66        1.5817  0.1163\n",
            "     67        1.7615  0.1148\n",
            "     68        0.8194  0.1130\n",
            "     69        2.2328  0.1105\n",
            "     70        1.7200  0.1142\n",
            "     71        1.4854  0.1367\n",
            "     72        0.9186  0.1315\n",
            "     73        2.0702  0.1175\n",
            "     74        1.1224  0.1159\n",
            "     75        1.7608  0.1205\n",
            "     76        1.1333  0.1201\n",
            "     77        2.2855  0.1171\n",
            "     78        1.2016  0.1349\n",
            "     79        2.6168  0.1183\n",
            "     80        2.2810  0.1587\n",
            "     81        1.6445  0.1226\n",
            "     82        3.1662  0.1230\n",
            "     83        1.7555  0.1260\n",
            "     84        2.6673  0.1418\n",
            "     85        2.9329  0.1085\n",
            "     86        2.7723  0.0880\n",
            "     87        2.3478  0.0882\n",
            "     88        2.3126  0.0806\n",
            "     89        3.0255  0.0939\n",
            "     90        2.2874  0.0879\n",
            "     91        2.1498  0.0836\n",
            "     92        2.3059  0.0799\n",
            "     93        1.6987  0.0867\n",
            "     94        2.1185  0.0946\n",
            "     95        2.0469  0.0936\n",
            "     96        2.8364  0.0837\n",
            "     97        2.3445  0.0825\n",
            "     98        2.6127  0.0850\n",
            "     99        2.3004  0.0895\n",
            "    100        2.2937  0.0984\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m39485.1919\u001b[0m  0.0820\n",
            "      2    \u001b[36m31892.7809\u001b[0m  0.0933\n",
            "      3    \u001b[36m25572.1622\u001b[0m  0.0832\n",
            "      4    \u001b[36m20450.2270\u001b[0m  0.0836\n",
            "      5    \u001b[36m16271.1802\u001b[0m  0.0947\n",
            "      6    \u001b[36m12843.6584\u001b[0m  0.0822\n",
            "      7    \u001b[36m10008.9198\u001b[0m  0.1092\n",
            "      8     \u001b[36m7634.9777\u001b[0m  0.0901\n",
            "      9     \u001b[36m5615.4933\u001b[0m  0.0849\n",
            "     10     \u001b[36m3861.3225\u001b[0m  0.0804\n",
            "     11     \u001b[36m2259.9998\u001b[0m  0.0927\n",
            "     12      \u001b[36m737.0217\u001b[0m  0.0818\n",
            "     13      \u001b[36m100.4580\u001b[0m  0.0834\n",
            "     14       \u001b[36m97.9167\u001b[0m  0.0845\n",
            "     15       \u001b[36m87.0995\u001b[0m  0.0905\n",
            "     16       \u001b[36m79.0017\u001b[0m  0.0847\n",
            "     17       \u001b[36m73.4496\u001b[0m  0.0931\n",
            "     18       \u001b[36m66.6348\u001b[0m  0.0886\n",
            "     19       \u001b[36m60.2889\u001b[0m  0.0948\n",
            "     20       \u001b[36m53.4925\u001b[0m  0.0848\n",
            "     21       \u001b[36m47.0936\u001b[0m  0.0800\n",
            "     22       \u001b[36m43.8427\u001b[0m  0.0859\n",
            "     23       \u001b[36m40.4690\u001b[0m  0.0980\n",
            "     24       \u001b[36m37.1897\u001b[0m  0.0803\n",
            "     25       \u001b[36m36.1480\u001b[0m  0.0818\n",
            "     26       \u001b[36m35.5027\u001b[0m  0.0944\n",
            "     27       \u001b[36m31.4472\u001b[0m  0.1012\n",
            "     28       \u001b[36m29.6803\u001b[0m  0.0815\n",
            "     29       \u001b[36m28.4316\u001b[0m  0.0903\n",
            "     30       \u001b[36m26.1011\u001b[0m  0.0839\n",
            "     31       \u001b[36m25.0971\u001b[0m  0.0831\n",
            "     32       \u001b[36m22.2043\u001b[0m  0.0829\n",
            "     33       \u001b[36m21.9288\u001b[0m  0.0850\n",
            "     34       \u001b[36m20.4198\u001b[0m  0.0946\n",
            "     35       \u001b[36m19.3171\u001b[0m  0.0792\n",
            "     36       \u001b[36m17.6137\u001b[0m  0.0879\n",
            "     37       \u001b[36m16.4221\u001b[0m  0.0854\n",
            "     38       \u001b[36m15.6475\u001b[0m  0.0840\n",
            "     39       16.3629  0.0824\n",
            "     40       \u001b[36m14.6889\u001b[0m  0.0887\n",
            "     41       \u001b[36m14.3116\u001b[0m  0.0879\n",
            "     42       14.3325  0.0841\n",
            "     43       \u001b[36m13.8887\u001b[0m  0.0902\n",
            "     44       \u001b[36m13.3254\u001b[0m  0.0871\n",
            "     45       \u001b[36m13.2315\u001b[0m  0.0881\n",
            "     46       \u001b[36m12.7738\u001b[0m  0.0994\n",
            "     47       \u001b[36m12.6036\u001b[0m  0.0837\n",
            "     48       \u001b[36m12.0952\u001b[0m  0.0840\n",
            "     49       \u001b[36m10.5027\u001b[0m  0.0809\n",
            "     50       \u001b[36m10.3027\u001b[0m  0.0858\n",
            "     51       \u001b[36m10.2937\u001b[0m  0.0964\n",
            "     52        \u001b[36m9.8782\u001b[0m  0.0828\n",
            "     53        \u001b[36m9.4863\u001b[0m  0.0939\n",
            "     54        \u001b[36m9.1805\u001b[0m  0.0844\n",
            "     55        \u001b[36m8.8263\u001b[0m  0.0855\n",
            "     56        \u001b[36m8.5703\u001b[0m  0.0873\n",
            "     57        \u001b[36m8.5569\u001b[0m  0.0934\n",
            "     58        \u001b[36m8.3755\u001b[0m  0.0819\n",
            "     59        \u001b[36m8.0837\u001b[0m  0.0850\n",
            "     60        8.1739  0.0825\n",
            "     61        \u001b[36m7.4868\u001b[0m  0.0886\n",
            "     62        7.8163  0.0812\n",
            "     63        7.7081  0.0868\n",
            "     64        7.8286  0.0915\n",
            "     65        \u001b[36m6.9707\u001b[0m  0.0852\n",
            "     66        \u001b[36m6.5846\u001b[0m  0.0856\n",
            "     67        \u001b[36m6.3411\u001b[0m  0.0896\n",
            "     68        6.4243  0.0897\n",
            "     69        \u001b[36m6.1724\u001b[0m  0.0836\n",
            "     70        6.3794  0.0833\n",
            "     71        6.2524  0.0932\n",
            "     72        6.3113  0.0866\n",
            "     73        6.2393  0.0853\n",
            "     74        6.5807  0.0914\n",
            "     75        6.8044  0.0870\n",
            "     76        6.4033  0.0839\n",
            "     77        6.4276  0.0888\n",
            "     78        6.3759  0.0890\n",
            "     79        6.3465  0.0841\n",
            "     80        \u001b[36m6.1672\u001b[0m  0.0980\n",
            "     81        \u001b[36m5.5546\u001b[0m  0.0853\n",
            "     82        \u001b[36m5.0609\u001b[0m  0.0925\n",
            "     83        \u001b[36m4.9546\u001b[0m  0.0863\n",
            "     84        5.0016  0.0906\n",
            "     85        5.0704  0.0844\n",
            "     86        5.0627  0.0864\n",
            "     87        \u001b[36m4.3441\u001b[0m  0.0845\n",
            "     88        4.4482  0.0896\n",
            "     89        4.5423  0.0825\n",
            "     90        \u001b[36m4.2590\u001b[0m  0.0862\n",
            "     91        4.6256  0.0977\n",
            "     92        \u001b[36m3.6895\u001b[0m  0.0891\n",
            "     93        4.8699  0.0828\n",
            "     94        \u001b[36m3.6426\u001b[0m  0.0919\n",
            "     95        \u001b[36m3.5508\u001b[0m  0.1137\n",
            "     96        3.7321  0.1180\n",
            "     97        4.7440  0.1253\n",
            "     98        4.5451  0.1251\n",
            "     99        \u001b[36m3.5097\u001b[0m  0.1178\n",
            "    100        4.1620  0.1170\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m25197.6005\u001b[0m  0.1138\n",
            "      2    \u001b[36m19566.8209\u001b[0m  0.1210\n",
            "      3    \u001b[36m15011.0767\u001b[0m  0.1225\n",
            "      4    \u001b[36m11389.3019\u001b[0m  0.1261\n",
            "      5     \u001b[36m8491.7596\u001b[0m  0.1275\n",
            "      6     \u001b[36m6150.3051\u001b[0m  0.1316\n",
            "      7     \u001b[36m4234.3491\u001b[0m  0.1158\n",
            "      8     \u001b[36m2630.5268\u001b[0m  0.1333\n",
            "      9     \u001b[36m1217.4798\u001b[0m  0.1273\n",
            "     10      \u001b[36m120.5507\u001b[0m  0.1241\n",
            "     11        \u001b[36m4.6677\u001b[0m  0.1226\n",
            "     12        \u001b[36m3.3898\u001b[0m  0.1450\n",
            "     13        3.4731  0.1374\n",
            "     14        3.4573  0.1285\n",
            "     15        3.4628  0.1206\n",
            "     16        3.4955  0.1273\n",
            "     17        3.5705  0.1288\n",
            "     18        3.6282  0.0831\n",
            "     19        3.6150  0.0840\n",
            "     20        3.6610  0.0911\n",
            "     21        3.7656  0.0830\n",
            "     22        3.7778  0.0869\n",
            "     23        3.7766  0.0903\n",
            "     24        3.8531  0.0819\n",
            "     25        3.8067  0.0823\n",
            "     26        3.9797  0.0881\n",
            "     27        3.9504  0.0977\n",
            "     28        3.8012  0.0867\n",
            "     29        3.8333  0.0935\n",
            "     30        3.8337  0.0881\n",
            "     31        3.8523  0.0912\n",
            "     32        3.6083  0.0863\n",
            "     33        3.6776  0.0968\n",
            "     34        3.6079  0.0825\n",
            "     35        3.6453  0.0825\n",
            "     36        3.6497  0.0911\n",
            "     37        3.6242  0.0854\n",
            "     38        3.6114  0.0881\n",
            "     39        3.6064  0.0942\n",
            "     40        3.8366  0.0881\n",
            "     41        3.9615  0.0923\n",
            "     42        \u001b[36m3.1381\u001b[0m  0.0880\n",
            "     43        4.1915  0.0827\n",
            "     44        \u001b[36m3.1137\u001b[0m  0.0848\n",
            "     45        4.3230  0.0847\n",
            "     46        3.1895  0.0812\n",
            "     47        3.4449  0.0797\n",
            "     48        3.3512  0.0811\n",
            "     49        3.5126  0.0894\n",
            "     50        3.3655  0.0975\n",
            "     51        \u001b[36m2.8778\u001b[0m  0.0990\n",
            "     52        4.0399  0.0822\n",
            "     53        3.7913  0.0841\n",
            "     54        3.1034  0.0926\n",
            "     55        4.0543  0.0878\n",
            "     56        3.2235  0.0819\n",
            "     57        4.3470  0.0862\n",
            "     58        6.6967  0.0834\n",
            "     59        9.1508  0.0868\n",
            "     60        5.8438  0.0822\n",
            "     61        4.4530  0.0955\n",
            "     62        3.2834  0.0940\n",
            "     63        3.2519  0.0848\n",
            "     64        4.2160  0.0873\n",
            "     65        3.4106  0.0882\n",
            "     66        3.8012  0.0865\n",
            "     67        3.2666  0.0818\n",
            "     68        4.1193  0.0807\n",
            "     69        3.6551  0.0890\n",
            "     70        4.4190  0.0808\n",
            "     71        7.1466  0.0875\n",
            "     72        6.7772  0.0929\n",
            "     73       10.6494  0.0981\n",
            "     74        4.5250  0.0871\n",
            "     75        3.3973  0.0872\n",
            "     76        3.4820  0.0849\n",
            "     77        3.6357  0.0827\n",
            "     78        3.6545  0.0823\n",
            "     79        4.4079  0.0866\n",
            "     80        4.9576  0.0813\n",
            "     81        6.8683  0.0842\n",
            "     82        8.6319  0.0833\n",
            "     83        6.2048  0.0928\n",
            "     84        6.0755  0.0896\n",
            "     85        6.0014  0.1001\n",
            "     86        5.9404  0.0831\n",
            "     87        6.7537  0.0931\n",
            "     88        5.8053  0.0816\n",
            "     89        5.1639  0.0898\n",
            "     90        4.0962  0.0887\n",
            "     91        3.5980  0.0831\n",
            "     92        3.4863  0.0818\n",
            "     93        3.5633  0.0837\n",
            "     94        3.5869  0.0992\n",
            "     95        3.6355  0.0926\n",
            "     96        3.6322  0.1058\n",
            "     97        3.7752  0.0837\n",
            "     98        3.6831  0.0804\n",
            "     99        4.6250  0.0801\n",
            "    100        8.4914  0.0999\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m40653.2219\u001b[0m  0.0841\n",
            "      2    \u001b[36m32257.0213\u001b[0m  0.0865\n",
            "      3    \u001b[36m25258.9891\u001b[0m  0.0970\n",
            "      4    \u001b[36m19501.2842\u001b[0m  0.0899\n",
            "      5    \u001b[36m14702.8958\u001b[0m  0.0895\n",
            "      6    \u001b[36m10649.9863\u001b[0m  0.0891\n",
            "      7     \u001b[36m7146.3835\u001b[0m  0.1002\n",
            "      8     \u001b[36m3978.9078\u001b[0m  0.0845\n",
            "      9     \u001b[36m1047.7729\u001b[0m  0.0840\n",
            "     10       \u001b[36m27.5294\u001b[0m  0.0866\n",
            "     11        \u001b[36m1.6264\u001b[0m  0.0822\n",
            "     12        1.9046  0.0889\n",
            "     13        1.9967  0.0833\n",
            "     14        1.9807  0.0826\n",
            "     15        1.9362  0.0885\n",
            "     16        1.8904  0.0862\n",
            "     17        1.9123  0.0869\n",
            "     18        2.0328  0.1089\n",
            "     19        1.6559  0.0811\n",
            "     20        1.9176  0.0792\n",
            "     21        1.6955  0.0869\n",
            "     22        2.0945  0.0932\n",
            "     23        \u001b[36m1.4303\u001b[0m  0.0851\n",
            "     24        1.4883  0.0801\n",
            "     25        1.5934  0.0878\n",
            "     26        \u001b[36m1.4280\u001b[0m  0.0797\n",
            "     27        \u001b[36m1.3937\u001b[0m  0.0893\n",
            "     28        \u001b[36m1.3802\u001b[0m  0.1240\n",
            "     29        1.4158  0.1347\n",
            "     30        1.6303  0.1187\n",
            "     31        1.4019  0.1217\n",
            "     32        1.4558  0.1189\n",
            "     33        2.5725  0.1130\n",
            "     34        2.0626  0.1161\n",
            "     35        2.4269  0.1152\n",
            "     36        2.6014  0.1162\n",
            "     37        2.0518  0.1362\n",
            "     38        1.4055  0.1278\n",
            "     39        1.6707  0.1238\n",
            "     40        2.3544  0.1193\n",
            "     41        2.3425  0.1158\n",
            "     42        2.4040  0.1249\n",
            "     43        2.2679  0.1312\n",
            "     44        2.6906  0.1440\n",
            "     45        1.9204  0.1227\n",
            "     46        3.4138  0.1473\n",
            "     47        1.9669  0.1357\n",
            "     48        2.1929  0.1271\n",
            "     49        2.0836  0.1161\n",
            "     50        5.2699  0.1307\n",
            "     51        2.4190  0.1391\n",
            "     52        2.3585  0.0853\n",
            "     53        3.3790  0.0844\n",
            "     54        2.2533  0.0919\n",
            "     55        2.0908  0.0851\n",
            "     56        2.7434  0.0820\n",
            "     57        1.7460  0.0850\n",
            "     58        1.8913  0.0860\n",
            "     59        3.4566  0.0841\n",
            "     60        2.2995  0.0862\n",
            "     61        1.8666  0.0911\n",
            "     62        1.6109  0.0831\n",
            "     63        3.2034  0.0885\n",
            "     64        5.2174  0.0894\n",
            "     65        2.6393  0.0964\n",
            "     66        2.5910  0.0956\n",
            "     67        2.1488  0.0844\n",
            "     68        1.6974  0.0868\n",
            "     69        2.1388  0.0822\n",
            "     70        3.0301  0.0820\n",
            "     71        3.5958  0.0877\n",
            "     72        3.7789  0.0826\n",
            "     73        2.0050  0.0847\n",
            "     74        3.1198  0.1022\n",
            "     75        2.6401  0.0845\n",
            "     76        3.1277  0.0897\n",
            "     77        2.5947  0.1050\n",
            "     78        4.0429  0.0874\n",
            "     79        2.0676  0.0834\n",
            "     80        2.1189  0.0815\n",
            "     81        2.1946  0.0800\n",
            "     82        2.1973  0.0827\n",
            "     83        2.0262  0.0831\n",
            "     84        2.0327  0.0995\n",
            "     85        5.7712  0.0966\n",
            "     86        2.0512  0.0868\n",
            "     87        2.2130  0.0832\n",
            "     88        2.6419  0.1065\n",
            "     89        2.6324  0.1001\n",
            "     90        1.6014  0.0865\n",
            "     91        2.6198  0.0836\n",
            "     92        2.3040  0.0854\n",
            "     93        2.3187  0.0829\n",
            "     94        4.0880  0.0885\n",
            "     95        1.5589  0.0883\n",
            "     96        1.9797  0.1016\n",
            "     97        4.1120  0.0864\n",
            "     98        4.9977  0.0836\n",
            "     99        2.1532  0.0992\n",
            "    100        1.5634  0.0848\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m27592.4620\u001b[0m  0.0770\n",
            "      2    \u001b[36m21371.8643\u001b[0m  0.0870\n",
            "      3    \u001b[36m16310.0514\u001b[0m  0.0898\n",
            "      4    \u001b[36m12267.9412\u001b[0m  0.0897\n",
            "      5     \u001b[36m9028.0403\u001b[0m  0.0931\n",
            "      6     \u001b[36m6415.0148\u001b[0m  0.1039\n",
            "      7     \u001b[36m4270.2652\u001b[0m  0.0915\n",
            "      8     \u001b[36m2442.0670\u001b[0m  0.0918\n",
            "      9      \u001b[36m800.9699\u001b[0m  0.0998\n",
            "     10       \u001b[36m14.5997\u001b[0m  0.0925\n",
            "     11        \u001b[36m6.3183\u001b[0m  0.0808\n",
            "     12        \u001b[36m6.1718\u001b[0m  0.0911\n",
            "     13        \u001b[36m5.3119\u001b[0m  0.0800\n",
            "     14        \u001b[36m5.1534\u001b[0m  0.0858\n",
            "     15        \u001b[36m4.9440\u001b[0m  0.1036\n",
            "     16        \u001b[36m4.8702\u001b[0m  0.0934\n",
            "     17        5.0080  0.0895\n",
            "     18        5.0434  0.1046\n",
            "     19        \u001b[36m4.8479\u001b[0m  0.0854\n",
            "     20        \u001b[36m4.5800\u001b[0m  0.0863\n",
            "     21        \u001b[36m4.3139\u001b[0m  0.0984\n",
            "     22        \u001b[36m3.8157\u001b[0m  0.0846\n",
            "     23        3.9297  0.0881\n",
            "     24        4.0462  0.0895\n",
            "     25        \u001b[36m3.8037\u001b[0m  0.0942\n",
            "     26        \u001b[36m3.3770\u001b[0m  0.0817\n",
            "     27        \u001b[36m3.1373\u001b[0m  0.0830\n",
            "     28        \u001b[36m3.0991\u001b[0m  0.0887\n",
            "     29        \u001b[36m3.0428\u001b[0m  0.0896\n",
            "     30        \u001b[36m3.0282\u001b[0m  0.0823\n",
            "     31        \u001b[36m2.7563\u001b[0m  0.0955\n",
            "     32        \u001b[36m2.7144\u001b[0m  0.0837\n",
            "     33        \u001b[36m2.6873\u001b[0m  0.0860\n",
            "     34        \u001b[36m2.5517\u001b[0m  0.0879\n",
            "     35        2.5925  0.0823\n",
            "     36        \u001b[36m2.4562\u001b[0m  0.0834\n",
            "     37        2.5484  0.0940\n",
            "     38        2.5659  0.0833\n",
            "     39        2.5688  0.0917\n",
            "     40        2.5746  0.0868\n",
            "     41        2.5121  0.0910\n",
            "     42        \u001b[36m2.2109\u001b[0m  0.0885\n",
            "     43        2.3245  0.0894\n",
            "     44        2.4611  0.0954\n",
            "     45        2.6708  0.0868\n",
            "     46        2.4001  0.0877\n",
            "     47        2.4373  0.0853\n",
            "     48        3.0491  0.0834\n",
            "     49        4.1209  0.0922\n",
            "     50        3.9569  0.0972\n",
            "     51        2.8629  0.0804\n",
            "     52        2.4879  0.0857\n",
            "     53        \u001b[36m2.1297\u001b[0m  0.0912\n",
            "     54        2.1473  0.0857\n",
            "     55        \u001b[36m2.0153\u001b[0m  0.0958\n",
            "     56        2.3813  0.0863\n",
            "     57        3.2895  0.0812\n",
            "     58        3.0237  0.0822\n",
            "     59        2.1007  0.0976\n",
            "     60        3.2175  0.0845\n",
            "     61        2.3067  0.1264\n",
            "     62        2.5587  0.1260\n",
            "     63        3.6812  0.1207\n",
            "     64        2.2659  0.1229\n",
            "     65        2.2585  0.1202\n",
            "     66        \u001b[36m1.9517\u001b[0m  0.1139\n",
            "     67        2.0649  0.1145\n",
            "     68        2.3103  0.1199\n",
            "     69        2.4439  0.1234\n",
            "     70        \u001b[36m1.9348\u001b[0m  0.1160\n",
            "     71        2.3370  0.1150\n",
            "     72        2.2040  0.1153\n",
            "     73        2.0091  0.1501\n",
            "     74        2.2243  0.1226\n",
            "     75        \u001b[36m1.7741\u001b[0m  0.1235\n",
            "     76        1.8912  0.1253\n",
            "     77        \u001b[36m1.7398\u001b[0m  0.1204\n",
            "     78        \u001b[36m1.7091\u001b[0m  0.1306\n",
            "     79        \u001b[36m1.6252\u001b[0m  0.1302\n",
            "     80        1.6899  0.1329\n",
            "     81        1.7233  0.1286\n",
            "     82        1.6723  0.1224\n",
            "     83        1.7078  0.1374\n",
            "     84        1.6920  0.0827\n",
            "     85        2.3925  0.0932\n",
            "     86        2.8109  0.0870\n",
            "     87        1.7007  0.0843\n",
            "     88        1.6452  0.0883\n",
            "     89        2.0310  0.0898\n",
            "     90        \u001b[36m1.4388\u001b[0m  0.0913\n",
            "     91        1.4495  0.0856\n",
            "     92        1.4404  0.0941\n",
            "     93        1.7802  0.0861\n",
            "     94        2.4089  0.0845\n",
            "     95        1.7853  0.0925\n",
            "     96        1.6160  0.0834\n",
            "     97        1.7402  0.0819\n",
            "     98        2.1751  0.0877\n",
            "     99        1.5541  0.0933\n",
            "    100        1.5592  0.0858\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m29695.6137\u001b[0m  0.0849\n",
            "      2    \u001b[36m23047.0135\u001b[0m  0.0903\n",
            "      3    \u001b[36m17579.4404\u001b[0m  0.0950\n",
            "      4    \u001b[36m13180.2446\u001b[0m  0.0864\n",
            "      5     \u001b[36m9656.9013\u001b[0m  0.0881\n",
            "      6     \u001b[36m6761.8167\u001b[0m  0.0832\n",
            "      7     \u001b[36m4320.1266\u001b[0m  0.0822\n",
            "      8     \u001b[36m2179.5170\u001b[0m  0.0866\n",
            "      9      \u001b[36m388.0943\u001b[0m  0.0851\n",
            "     10       \u001b[36m14.5285\u001b[0m  0.0802\n",
            "     11        \u001b[36m5.7474\u001b[0m  0.0883\n",
            "     12        \u001b[36m4.4281\u001b[0m  0.0798\n",
            "     13        4.8884  0.0806\n",
            "     14        4.7915  0.0810\n",
            "     15        5.0067  0.1043\n",
            "     16        6.7617  0.0814\n",
            "     17        7.5314  0.0804\n",
            "     18        6.0996  0.0878\n",
            "     19        6.1095  0.0920\n",
            "     20        5.5378  0.0820\n",
            "     21        5.0808  0.0812\n",
            "     22        5.3184  0.0889\n",
            "     23        \u001b[36m4.3714\u001b[0m  0.0827\n",
            "     24        5.3574  0.0837\n",
            "     25        4.8372  0.0869\n",
            "     26        4.7633  0.0953\n",
            "     27        5.2577  0.0890\n",
            "     28        5.2781  0.0810\n",
            "     29        5.1697  0.0987\n",
            "     30        5.3997  0.0827\n",
            "     31        5.4993  0.0846\n",
            "     32        5.7136  0.0914\n",
            "     33        6.3682  0.0824\n",
            "     34        9.5859  0.0854\n",
            "     35        9.5027  0.0855\n",
            "     36        8.4398  0.0821\n",
            "     37        6.0229  0.0816\n",
            "     38        6.0857  0.0974\n",
            "     39        6.7185  0.0861\n",
            "     40        9.6416  0.0869\n",
            "     41        8.9260  0.0846\n",
            "     42        5.6689  0.0844\n",
            "     43        5.1596  0.0836\n",
            "     44        5.4840  0.0816\n",
            "     45        5.5157  0.0909\n",
            "     46        5.7401  0.0810\n",
            "     47        8.4411  0.0809\n",
            "     48       11.5338  0.0843\n",
            "     49       12.2063  0.1038\n",
            "     50       10.1587  0.0976\n",
            "     51        9.6118  0.0844\n",
            "     52        8.2199  0.0974\n",
            "     53        5.5007  0.0931\n",
            "     54        5.5870  0.0903\n",
            "     55        5.7864  0.0915\n",
            "     56        5.8934  0.0908\n",
            "     57        5.8601  0.0986\n",
            "     58        6.0224  0.0891\n",
            "     59        9.6382  0.0886\n",
            "     60       11.7653  0.0951\n",
            "     61       11.2971  0.0921\n",
            "     62       11.2702  0.0905\n",
            "     63        8.3230  0.0814\n",
            "     64        4.6801  0.0834\n",
            "     65        6.2183  0.0926\n",
            "     66        7.5443  0.0815\n",
            "     67        7.2677  0.0848\n",
            "     68        7.9211  0.0846\n",
            "     69        7.6942  0.0844\n",
            "     70        6.5356  0.0833\n",
            "     71        8.2870  0.0881\n",
            "     72        7.5468  0.1009\n",
            "     73        7.9106  0.0853\n",
            "     74        6.7530  0.0827\n",
            "     75        8.1947  0.0844\n",
            "     76        8.2163  0.0848\n",
            "     77        6.8228  0.0810\n",
            "     78       10.1987  0.0887\n",
            "     79       12.3326  0.0812\n",
            "     80       11.7538  0.0830\n",
            "     81        8.8873  0.0899\n",
            "     82        4.4595  0.0885\n",
            "     83        6.7694  0.0924\n",
            "     84        6.0066  0.0869\n",
            "     85        6.4936  0.0860\n",
            "     86       10.4005  0.0894\n",
            "     87       11.3312  0.0954\n",
            "     88        8.7245  0.0867\n",
            "     89        6.1582  0.0837\n",
            "     90        5.4605  0.0846\n",
            "     91        6.2784  0.0905\n",
            "     92        5.5332  0.0876\n",
            "     93        7.0394  0.0832\n",
            "     94        8.3612  0.1206\n",
            "     95        5.7134  0.1357\n",
            "     96        7.1977  0.1206\n",
            "     97        8.9865  0.1293\n",
            "     98        6.5315  0.1230\n",
            "     99        7.1954  0.1266\n",
            "    100       12.7546  0.1165\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m23259.4486\u001b[0m  0.1153\n",
            "      2    \u001b[36m17902.5205\u001b[0m  0.1547\n",
            "      3    \u001b[36m13563.7426\u001b[0m  0.1227\n",
            "      4    \u001b[36m10106.1746\u001b[0m  0.1327\n",
            "      5     \u001b[36m7319.9062\u001b[0m  0.1183\n",
            "      6     \u001b[36m5028.5432\u001b[0m  0.1377\n",
            "      7     \u001b[36m3082.1667\u001b[0m  0.1304\n",
            "      8     \u001b[36m1335.9329\u001b[0m  0.1402\n",
            "      9      \u001b[36m117.0057\u001b[0m  0.1379\n",
            "     10       \u001b[36m10.9947\u001b[0m  0.1386\n",
            "     11        \u001b[36m0.7923\u001b[0m  0.1437\n",
            "     12        0.9131  0.1207\n",
            "     13        \u001b[36m0.7746\u001b[0m  0.1270\n",
            "     14        \u001b[36m0.6866\u001b[0m  0.1242\n",
            "     15        \u001b[36m0.6426\u001b[0m  0.1241\n",
            "     16        \u001b[36m0.6161\u001b[0m  0.1179\n",
            "     17        \u001b[36m0.5645\u001b[0m  0.0829\n",
            "     18        \u001b[36m0.5469\u001b[0m  0.0990\n",
            "     19        0.5733  0.1071\n",
            "     20        0.6200  0.0919\n",
            "     21        0.7167  0.0847\n",
            "     22        0.7455  0.0916\n",
            "     23        1.1018  0.0850\n",
            "     24        1.2503  0.0832\n",
            "     25        1.2871  0.0835\n",
            "     26        1.3290  0.0879\n",
            "     27        1.5828  0.0838\n",
            "     28        2.4254  0.0863\n",
            "     29        1.4625  0.0906\n",
            "     30        2.5228  0.0884\n",
            "     31        1.3959  0.0810\n",
            "     32        1.6975  0.0876\n",
            "     33        2.7264  0.0844\n",
            "     34        2.9288  0.0821\n",
            "     35        2.1329  0.0801\n",
            "     36        2.7946  0.0852\n",
            "     37        2.5914  0.0832\n",
            "     38        1.4144  0.0869\n",
            "     39        1.0939  0.0842\n",
            "     40        1.5588  0.0846\n",
            "     41        3.4952  0.0813\n",
            "     42        1.6457  0.0938\n",
            "     43        1.5674  0.0880\n",
            "     44        1.7592  0.0806\n",
            "     45        1.9389  0.0807\n",
            "     46        3.4949  0.0884\n",
            "     47        1.9282  0.0840\n",
            "     48        2.0790  0.0877\n",
            "     49        2.6780  0.0899\n",
            "     50        3.3558  0.0909\n",
            "     51        2.0859  0.0827\n",
            "     52        1.7766  0.0883\n",
            "     53        1.3137  0.1075\n",
            "     54        1.9037  0.0807\n",
            "     55        3.0301  0.0864\n",
            "     56        3.7536  0.0842\n",
            "     57        2.3569  0.0901\n",
            "     58        3.3056  0.0893\n",
            "     59        3.0462  0.0887\n",
            "     60        2.7174  0.0860\n",
            "     61        1.8145  0.1007\n",
            "     62        1.2847  0.0880\n",
            "     63        1.3662  0.0809\n",
            "     64        1.6204  0.1027\n",
            "     65        1.9760  0.0844\n",
            "     66        2.5726  0.0867\n",
            "     67        3.4563  0.0840\n",
            "     68        2.0282  0.0876\n",
            "     69        1.3453  0.0815\n",
            "     70        2.2370  0.0824\n",
            "     71        2.4045  0.0958\n",
            "     72        2.1932  0.0838\n",
            "     73        2.4479  0.0851\n",
            "     74        2.3478  0.0962\n",
            "     75        2.3286  0.0929\n",
            "     76        2.4915  0.0919\n",
            "     77        6.7131  0.0786\n",
            "     78        4.3986  0.0863\n",
            "     79        1.6960  0.0836\n",
            "     80        1.4536  0.0806\n",
            "     81        1.5868  0.0828\n",
            "     82        1.4769  0.0861\n",
            "     83        2.5180  0.0836\n",
            "     84        3.8383  0.0791\n",
            "     85        4.5671  0.0831\n",
            "     86        1.6504  0.0805\n",
            "     87        1.4207  0.0980\n",
            "     88        1.6824  0.0832\n",
            "     89        1.4123  0.0815\n",
            "     90        2.4388  0.0906\n",
            "     91        2.5039  0.0835\n",
            "     92        1.8771  0.0824\n",
            "     93        2.7087  0.0822\n",
            "     94        3.2177  0.0934\n",
            "     95        2.6465  0.0921\n",
            "     96        1.6137  0.0829\n",
            "     97        1.6408  0.0849\n",
            "     98        2.7717  0.0968\n",
            "     99        4.3255  0.0984\n",
            "    100        2.7655  0.0949\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m31229.9732\u001b[0m  0.0811\n",
            "      2    \u001b[36m24432.8790\u001b[0m  0.0900\n",
            "      3    \u001b[36m18851.6039\u001b[0m  0.0923\n",
            "      4    \u001b[36m14364.2418\u001b[0m  0.1149\n",
            "      5    \u001b[36m10755.8854\u001b[0m  0.1005\n",
            "      6     \u001b[36m7821.0989\u001b[0m  0.0996\n",
            "      7     \u001b[36m5380.5380\u001b[0m  0.0926\n",
            "      8     \u001b[36m3281.2311\u001b[0m  0.0871\n",
            "      9     \u001b[36m1386.0064\u001b[0m  0.0949\n",
            "     10      \u001b[36m123.4123\u001b[0m  0.0816\n",
            "     11       \u001b[36m60.7861\u001b[0m  0.0964\n",
            "     12       62.0884  0.0865\n",
            "     13       \u001b[36m58.6588\u001b[0m  0.0820\n",
            "     14       \u001b[36m56.2897\u001b[0m  0.0946\n",
            "     15       56.3980  0.0847\n",
            "     16       \u001b[36m51.8088\u001b[0m  0.0806\n",
            "     17       \u001b[36m47.8759\u001b[0m  0.0861\n",
            "     18       49.2367  0.0887\n",
            "     19       \u001b[36m39.2033\u001b[0m  0.0837\n",
            "     20       \u001b[36m32.1681\u001b[0m  0.0791\n",
            "     21       \u001b[36m27.3199\u001b[0m  0.0896\n",
            "     22       \u001b[36m24.4725\u001b[0m  0.0875\n",
            "     23       \u001b[36m23.0616\u001b[0m  0.0864\n",
            "     24       \u001b[36m21.2975\u001b[0m  0.0828\n",
            "     25       \u001b[36m20.7692\u001b[0m  0.0834\n",
            "     26       \u001b[36m16.9794\u001b[0m  0.0907\n",
            "     27       \u001b[36m16.0689\u001b[0m  0.1318\n",
            "     28       \u001b[36m15.1208\u001b[0m  0.1411\n",
            "     29       \u001b[36m12.8534\u001b[0m  0.1241\n",
            "     30       \u001b[36m12.3152\u001b[0m  0.1229\n",
            "     31       12.8752  0.1339\n",
            "     32       12.3818  0.1207\n",
            "     33        \u001b[36m9.7287\u001b[0m  0.1201\n",
            "     34        \u001b[36m7.3816\u001b[0m  0.1195\n",
            "     35        9.4516  0.1165\n",
            "     36        7.5256  0.1157\n",
            "     37        \u001b[36m5.2116\u001b[0m  0.1388\n",
            "     38        6.1609  0.1186\n",
            "     39        6.5747  0.1191\n",
            "     40        \u001b[36m5.0172\u001b[0m  0.1270\n",
            "     41        6.0031  0.1226\n",
            "     42        5.9514  0.1131\n",
            "     43        5.9014  0.1143\n",
            "     44        6.5971  0.1491\n",
            "     45        5.2819  0.1396\n",
            "     46        5.6894  0.1243\n",
            "     47        6.9135  0.1427\n",
            "     48        5.6403  0.1443\n",
            "     49        5.7983  0.1016\n",
            "     50        \u001b[36m4.9027\u001b[0m  0.0904\n",
            "     51        \u001b[36m4.2299\u001b[0m  0.0892\n",
            "     52        \u001b[36m3.7287\u001b[0m  0.0892\n",
            "     53        \u001b[36m3.3549\u001b[0m  0.0875\n",
            "     54        3.5366  0.0834\n",
            "     55        3.5025  0.0832\n",
            "     56        3.5417  0.1003\n",
            "     57        3.5499  0.0877\n",
            "     58        3.5599  0.0837\n",
            "     59        3.5322  0.0910\n",
            "     60        3.5289  0.0889\n",
            "     61        3.4763  0.0827\n",
            "     62        3.3605  0.0829\n",
            "     63        \u001b[36m3.3454\u001b[0m  0.0873\n",
            "     64        \u001b[36m2.9325\u001b[0m  0.0819\n",
            "     65        2.9760  0.0806\n",
            "     66        \u001b[36m2.3892\u001b[0m  0.0902\n",
            "     67        2.9456  0.0897\n",
            "     68        2.9669  0.0979\n",
            "     69        \u001b[36m2.2281\u001b[0m  0.0930\n",
            "     70        \u001b[36m1.8754\u001b[0m  0.0911\n",
            "     71        \u001b[36m1.8205\u001b[0m  0.0854\n",
            "     72        \u001b[36m1.7010\u001b[0m  0.0850\n",
            "     73        \u001b[36m1.4875\u001b[0m  0.0957\n",
            "     74        \u001b[36m1.4448\u001b[0m  0.0817\n",
            "     75        \u001b[36m1.4044\u001b[0m  0.0868\n",
            "     76        1.5234  0.0908\n",
            "     77        1.4409  0.0885\n",
            "     78        1.4109  0.0855\n",
            "     79        \u001b[36m1.3439\u001b[0m  0.1001\n",
            "     80        \u001b[36m1.1940\u001b[0m  0.0877\n",
            "     81        \u001b[36m1.1697\u001b[0m  0.0862\n",
            "     82        1.1707  0.0801\n",
            "     83        1.2843  0.0949\n",
            "     84        1.1919  0.0907\n",
            "     85        1.2430  0.0857\n",
            "     86        1.5395  0.0841\n",
            "     87        1.7211  0.0843\n",
            "     88        1.6132  0.0821\n",
            "     89        1.2320  0.0875\n",
            "     90        1.3381  0.0939\n",
            "     91        1.8360  0.0821\n",
            "     92        1.3213  0.0811\n",
            "     93        2.1570  0.0891\n",
            "     94        1.6389  0.0884\n",
            "     95        1.7610  0.0839\n",
            "     96        1.3622  0.0812\n",
            "     97        2.0933  0.0955\n",
            "     98        1.1825  0.0822\n",
            "     99        1.3372  0.0807\n",
            "    100        1.9359  0.0857\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m24376.3316\u001b[0m  0.0896\n",
            "      2    \u001b[36m18794.9785\u001b[0m  0.0881\n",
            "      3    \u001b[36m14299.8640\u001b[0m  0.0955\n",
            "      4    \u001b[36m10690.5704\u001b[0m  0.0808\n",
            "      5     \u001b[36m7743.6165\u001b[0m  0.0930\n",
            "      6     \u001b[36m5281.4788\u001b[0m  0.0852\n",
            "      7     \u001b[36m3147.9956\u001b[0m  0.0838\n",
            "      8     \u001b[36m1189.0406\u001b[0m  0.0852\n",
            "      9       \u001b[36m47.4714\u001b[0m  0.0896\n",
            "     10       \u001b[36m25.7854\u001b[0m  0.0917\n",
            "     11       \u001b[36m21.3533\u001b[0m  0.0838\n",
            "     12       \u001b[36m19.3693\u001b[0m  0.0836\n",
            "     13       \u001b[36m16.9302\u001b[0m  0.1009\n",
            "     14       \u001b[36m16.9107\u001b[0m  0.0831\n",
            "     15       \u001b[36m15.5164\u001b[0m  0.0811\n",
            "     16       \u001b[36m12.6937\u001b[0m  0.0809\n",
            "     17       \u001b[36m10.9820\u001b[0m  0.0882\n",
            "     18        \u001b[36m8.2470\u001b[0m  0.0834\n",
            "     19        8.5230  0.0896\n",
            "     20        \u001b[36m7.7546\u001b[0m  0.0813\n",
            "     21        8.2151  0.0862\n",
            "     22        8.1133  0.0839\n",
            "     23        \u001b[36m7.1185\u001b[0m  0.0822\n",
            "     24        7.1575  0.0868\n",
            "     25        \u001b[36m7.1018\u001b[0m  0.0968\n",
            "     26        \u001b[36m6.8580\u001b[0m  0.0814\n",
            "     27        7.2570  0.0913\n",
            "     28        7.4838  0.0872\n",
            "     29        7.4710  0.0826\n",
            "     30        \u001b[36m6.2504\u001b[0m  0.0863\n",
            "     31        6.4018  0.0835\n",
            "     32        6.4677  0.0834\n",
            "     33        6.5317  0.0810\n",
            "     34        6.5906  0.0904\n",
            "     35        6.7199  0.0885\n",
            "     36        6.7943  0.0958\n",
            "     37        6.5704  0.0893\n",
            "     38        \u001b[36m6.1038\u001b[0m  0.0881\n",
            "     39        \u001b[36m5.4443\u001b[0m  0.0921\n",
            "     40        6.9254  0.0864\n",
            "     41        5.6841  0.0870\n",
            "     42        5.6238  0.0933\n",
            "     43        6.5600  0.0807\n",
            "     44        7.1644  0.0846\n",
            "     45        6.1500  0.0840\n",
            "     46        5.4591  0.0894\n",
            "     47        6.2247  0.1061\n",
            "     48        6.1213  0.0829\n",
            "     49        6.0866  0.0798\n",
            "     50        5.8729  0.0864\n",
            "     51        6.3111  0.0858\n",
            "     52        5.7018  0.0818\n",
            "     53        7.6434  0.0784\n",
            "     54        8.1012  0.0797\n",
            "     55        \u001b[36m5.3030\u001b[0m  0.0866\n",
            "     56        6.2416  0.0861\n",
            "     57        7.1302  0.0912\n",
            "     58        5.5273  0.0957\n",
            "     59        5.4311  0.1167\n",
            "     60        8.0104  0.1473\n",
            "     61        9.4166  0.1268\n",
            "     62        7.7737  0.1240\n",
            "     63        5.6055  0.1261\n",
            "     64        5.3846  0.1190\n",
            "     65        5.3119  0.1216\n",
            "     66        5.8779  0.1192\n",
            "     67        6.0216  0.1291\n",
            "     68        5.8884  0.1162\n",
            "     69        6.3355  0.1118\n",
            "     70        8.9475  0.1199\n",
            "     71        7.9524  0.1099\n",
            "     72        8.2122  0.1132\n",
            "     73        5.3965  0.1223\n",
            "     74        5.5616  0.1215\n",
            "     75        5.6438  0.1306\n",
            "     76        6.1510  0.1216\n",
            "     77        5.5998  0.1211\n",
            "     78        6.0411  0.1201\n",
            "     79        6.1972  0.1284\n",
            "     80        6.5227  0.1277\n",
            "     81        6.5138  0.1337\n",
            "     82        6.4886  0.1228\n",
            "     83        6.4725  0.0834\n",
            "     84        5.8172  0.1528\n",
            "     85        5.6525  0.1344\n",
            "     86        5.9345  0.1234\n",
            "     87        7.1732  0.1137\n",
            "     88        6.6676  0.1164\n",
            "     89        5.8708  0.1338\n",
            "     90        5.8268  0.1139\n",
            "     91        6.6816  0.1213\n",
            "     92        5.6414  0.1215\n",
            "     93        \u001b[36m4.7464\u001b[0m  0.1174\n",
            "     94        \u001b[36m4.7450\u001b[0m  0.1133\n",
            "     95        5.4816  0.1185\n",
            "     96        7.5589  0.1154\n",
            "     97        9.7822  0.1105\n",
            "     98        8.6003  0.1239\n",
            "     99        5.7594  0.1156\n",
            "    100        \u001b[36m4.7133\u001b[0m  0.1213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HOwEpLscI1U",
        "outputId": "5359f824-2a0e-426e-fd74-7bbdc320f23c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.87719298, 0.85964912, 0.94736842, 0.94736842, 0.87719298,\n",
              "       0.9122807 , 0.87719298, 0.9122807 , 0.75438596, 0.92857143])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwYjAXOZnhZt",
        "outputId": "bc37f551-fe38-4596-e7d3-696fd26d2e37"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8893483709273182"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados.std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds2j9wi6nj98",
        "outputId": "a26b105d-3979-4261-e65d-51f2630273c9"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.05372433439448073"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para evitar o overfiting realizaremos o Dropout, que é uma tecnica que consiste em apagar alguns neuronios (dropar) para evitar o overfiting para isso será construido outro classificador"
      ],
      "metadata": {
        "id": "rNlMeQxvn_C5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class classificadorTorchDropOut(nn.Module):\n",
        "  def __init__(self):\n",
        "    \"\"\"\n",
        "      a estrutura dessa rede neural é 30 -> 16 ->16->1\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "\n",
        "    # primeira camada densa com 30 entradas ligado a 16 neuronios\n",
        "    self.camada0 = nn.Linear(30,16)\n",
        "    torch.nn.init.uniform_(self.camada0.weight) # inicia os pesos com uma distribuição uniforme\n",
        "    self.camadaAtivacao0 = nn.ReLU()\n",
        "    self.camada0DropOut = nn.Dropout()\n",
        "\n",
        "    #segunda camada densa, cada camada oculta com 16 neuronios.\n",
        "    self.camada1 = nn.Linear(16,16)\n",
        "    torch.nn.init.uniform_(self.camada1.weight)\n",
        "    self.camadaAtivacao1 = nn.ReLU()\n",
        "    self.camada1DropOut = nn.Dropout()\n",
        "\n",
        "    #camda de saida densa, camada oculta para camada de saida 16->1\n",
        "    self.camadaSaida = nn.Linear(16,1)\n",
        "    torch.nn.init.uniform_(self.camadaSaida.weight)\n",
        "    # self.camadaAtivacaoSaida = nn.Sigmoid() #nesta versao nao precisa de sigmoid na saida, ele ja faz\n",
        "\n",
        "  def forward(self,valoresEntrada):\n",
        "    \"\"\"\n",
        "      Propagação dos valores dentro da rede neural\n",
        "    \"\"\"\n",
        "    elemento = self.camada0(valoresEntrada)\n",
        "    elemento = self.camadaAtivacao0(elemento)\n",
        "    elemento = self.camada0DropOut(elemento)\n",
        "\n",
        "    elemento = self.camada1(elemento)\n",
        "    elemento = self.camadaAtivacao1(elemento)\n",
        "    elemento = self.camada1DropOut(elemento)\n",
        "\n",
        "    elemento = self.camadaSaida(elemento)\n",
        "    # elemento = self.camadaAtivacaoSaida(elemento) #nesta versao nao precisa de sigmoid na saida, ele ja faz\n",
        "    return elemento"
      ],
      "metadata": {
        "id": "ecUEDhaFaBCr"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "classificador_sklearn_dropOut = NeuralNetBinaryClassifier(module = classificadorTorchDropOut,\\\n",
        "                                                  criterion = torch.nn.BCEWithLogitsLoss,\\\n",
        "                                                  optimizer = torch.optim.Adam,\\\n",
        "                                                  lr = 0.001 ,\\\n",
        "                                                  optimizer__weight_decay = 0.0001,\\\n",
        "                                                  max_epochs = 100,\\\n",
        "                                                  batch_size = 10,\\\n",
        "                                                  train_split = False,\\\n",
        "                                                  )"
      ],
      "metadata": {
        "id": "NELKVEnTrgRe"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_2 =cross_val_score(classificador_sklearn_dropOut, dsPreditores, dsAlvo, cv=10, scoring='accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo0vMD3YrEuc",
        "outputId": "d979ccfd-5d3e-4d8b-a675-8cfc5db7bee9"
      },
      "execution_count": 69,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m28340.6006\u001b[0m  0.1560\n",
            "      2    \u001b[36m22223.2715\u001b[0m  0.1446\n",
            "      3    \u001b[36m18100.3568\u001b[0m  0.1390\n",
            "      4    \u001b[36m13940.9384\u001b[0m  0.1564\n",
            "      5    \u001b[36m11856.9383\u001b[0m  0.3037\n",
            "      6     \u001b[36m9238.4950\u001b[0m  0.2089\n",
            "      7     \u001b[36m7248.0067\u001b[0m  0.1616\n",
            "      8     \u001b[36m5251.9737\u001b[0m  0.1003\n",
            "      9     \u001b[36m3776.0628\u001b[0m  0.0950\n",
            "     10     \u001b[36m2831.0475\u001b[0m  0.0998\n",
            "     11     \u001b[36m2093.4523\u001b[0m  0.0959\n",
            "     12     \u001b[36m1696.4836\u001b[0m  0.0988\n",
            "     13     \u001b[36m1515.7268\u001b[0m  0.0939\n",
            "     14     1528.2872  0.0908\n",
            "     15      \u001b[36m999.3610\u001b[0m  0.1794\n",
            "     16     1047.7006  0.1484\n",
            "     17     1029.2627  0.1334\n",
            "     18      \u001b[36m786.9834\u001b[0m  0.1092\n",
            "     19      811.5067  0.0881\n",
            "     20      \u001b[36m691.0421\u001b[0m  0.0970\n",
            "     21      720.5678  0.0919\n",
            "     22      \u001b[36m637.9953\u001b[0m  0.0998\n",
            "     23      \u001b[36m533.0970\u001b[0m  0.0956\n",
            "     24      \u001b[36m509.5313\u001b[0m  0.0975\n",
            "     25      \u001b[36m449.4963\u001b[0m  0.0934\n",
            "     26      \u001b[36m409.8008\u001b[0m  0.0925\n",
            "     27      \u001b[36m370.2640\u001b[0m  0.0877\n",
            "     28      \u001b[36m336.9753\u001b[0m  0.1035\n",
            "     29      \u001b[36m266.5409\u001b[0m  0.0890\n",
            "     30      \u001b[36m246.1351\u001b[0m  0.0856\n",
            "     31      \u001b[36m229.0967\u001b[0m  0.2259\n",
            "     32      251.1663  0.1665\n",
            "     33      \u001b[36m201.7929\u001b[0m  0.1530\n",
            "     34      \u001b[36m174.1627\u001b[0m  0.1707\n",
            "     35      176.7010  0.1483\n",
            "     36      \u001b[36m136.8358\u001b[0m  0.1615\n",
            "     37      139.7348  0.2014\n",
            "     38      \u001b[36m126.3525\u001b[0m  0.2312\n",
            "     39      \u001b[36m117.5677\u001b[0m  0.1668\n",
            "     40      \u001b[36m105.8495\u001b[0m  0.1899\n",
            "     41       \u001b[36m80.0094\u001b[0m  0.1783\n",
            "     42       80.9199  0.1716\n",
            "     43       80.0423  0.1809\n",
            "     44       \u001b[36m73.0587\u001b[0m  0.1614\n",
            "     45       74.1562  0.1600\n",
            "     46       \u001b[36m50.0646\u001b[0m  0.1479\n",
            "     47       55.7216  0.1936\n",
            "     48       50.2166  0.1741\n",
            "     49       \u001b[36m46.5340\u001b[0m  0.2399\n",
            "     50       \u001b[36m37.4523\u001b[0m  0.2308\n",
            "     51       \u001b[36m35.0873\u001b[0m  0.3892\n",
            "     52       \u001b[36m31.9873\u001b[0m  0.4658\n",
            "     53       33.2248  0.4596\n",
            "     54       \u001b[36m23.7482\u001b[0m  0.4601\n",
            "     55       \u001b[36m23.0741\u001b[0m  0.4245\n",
            "     56       \u001b[36m20.9957\u001b[0m  0.5909\n",
            "     57       \u001b[36m18.7921\u001b[0m  0.4584\n",
            "     58       20.1426  0.2475\n",
            "     59       \u001b[36m17.8921\u001b[0m  0.2511\n",
            "     60       \u001b[36m13.9926\u001b[0m  0.1648\n",
            "     61       \u001b[36m10.1142\u001b[0m  0.3469\n",
            "     62       11.1862  0.5695\n",
            "     63       11.0628  0.3163\n",
            "     64        \u001b[36m9.1957\u001b[0m  0.3287\n",
            "     65        \u001b[36m8.7076\u001b[0m  0.1807\n",
            "     66        \u001b[36m6.5770\u001b[0m  0.2043\n",
            "     67        \u001b[36m5.7908\u001b[0m  0.1349\n",
            "     68        6.0997  0.1549\n",
            "     69        \u001b[36m4.8191\u001b[0m  0.1361\n",
            "     70        5.2128  0.1584\n",
            "     71        5.8139  0.1743\n",
            "     72        \u001b[36m3.7171\u001b[0m  0.1791\n",
            "     73        4.8872  0.1946\n",
            "     74        \u001b[36m2.8975\u001b[0m  0.1576\n",
            "     75        3.0103  0.2775\n",
            "     76        \u001b[36m2.6895\u001b[0m  0.1511\n",
            "     77        4.0808  0.2712\n",
            "     78        \u001b[36m1.9476\u001b[0m  0.1507\n",
            "     79        \u001b[36m1.9326\u001b[0m  0.2318\n",
            "     80        2.3524  0.1785\n",
            "     81        \u001b[36m1.3263\u001b[0m  0.1267\n",
            "     82        2.0222  0.2638\n",
            "     83        1.9281  0.2624\n",
            "     84        \u001b[36m1.0391\u001b[0m  0.3075\n",
            "     85        1.1076  0.3169\n",
            "     86        1.0732  0.3185\n",
            "     87        1.0922  0.1665\n",
            "     88        \u001b[36m0.9213\u001b[0m  0.2783\n",
            "     89        \u001b[36m0.7478\u001b[0m  0.3114\n",
            "     90        1.0003  0.3539\n",
            "     91        0.8942  0.1293\n",
            "     92        1.1532  0.1592\n",
            "     93        0.7919  0.2677\n",
            "     94        \u001b[36m0.5642\u001b[0m  0.2168\n",
            "     95        1.1556  0.3274\n",
            "     96        0.6522  0.1908\n",
            "     97        \u001b[36m0.5635\u001b[0m  0.1552\n",
            "     98        1.1792  0.1870\n",
            "     99        0.8320  0.4355\n",
            "    100        0.6107  0.4424\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m33750.5038\u001b[0m  0.5263\n",
            "      2    \u001b[36m26969.8428\u001b[0m  0.5150\n",
            "      3    \u001b[36m22092.5031\u001b[0m  0.5891\n",
            "      4    \u001b[36m18306.4073\u001b[0m  0.4266\n",
            "      5    \u001b[36m14577.5803\u001b[0m  0.2549\n",
            "      6    \u001b[36m11998.7166\u001b[0m  0.1873\n",
            "      7     \u001b[36m9175.4853\u001b[0m  0.1711\n",
            "      8     \u001b[36m7538.0388\u001b[0m  0.2436\n",
            "      9     \u001b[36m5541.9582\u001b[0m  0.2017\n",
            "     10     \u001b[36m4637.8645\u001b[0m  0.2288\n",
            "     11     \u001b[36m3698.0046\u001b[0m  0.2081\n",
            "     12     \u001b[36m2416.8466\u001b[0m  0.5038\n",
            "     13     \u001b[36m1881.7373\u001b[0m  0.4951\n",
            "     14     \u001b[36m1386.1629\u001b[0m  0.2660\n",
            "     15     \u001b[36m1062.6027\u001b[0m  0.2370\n",
            "     16      \u001b[36m942.9705\u001b[0m  0.2239\n",
            "     17      \u001b[36m803.6547\u001b[0m  0.1400\n",
            "     18      \u001b[36m755.0911\u001b[0m  0.1632\n",
            "     19      \u001b[36m687.7109\u001b[0m  0.1748\n",
            "     20      \u001b[36m616.9276\u001b[0m  0.1926\n",
            "     21      \u001b[36m577.3646\u001b[0m  0.2288\n",
            "     22      \u001b[36m523.7822\u001b[0m  0.1678\n",
            "     23      \u001b[36m483.8932\u001b[0m  0.1336\n",
            "     24      \u001b[36m444.8378\u001b[0m  0.2329\n",
            "     25      \u001b[36m358.0398\u001b[0m  0.1549\n",
            "     26      391.5843  0.1700\n",
            "     27      358.0694  0.1709\n",
            "     28      \u001b[36m317.1365\u001b[0m  0.1582\n",
            "     29      \u001b[36m301.4061\u001b[0m  0.1383\n",
            "     30      \u001b[36m255.0020\u001b[0m  0.2071\n",
            "     31      275.8973  0.2345\n",
            "     32      \u001b[36m231.4209\u001b[0m  0.2635\n",
            "     33      \u001b[36m205.0146\u001b[0m  0.1825\n",
            "     34      \u001b[36m198.3540\u001b[0m  0.1015\n",
            "     35      198.4753  0.0895\n",
            "     36      \u001b[36m168.0237\u001b[0m  0.0985\n",
            "     37      178.4123  0.0992\n",
            "     38      \u001b[36m153.8973\u001b[0m  0.0918\n",
            "     39      \u001b[36m126.6774\u001b[0m  0.0906\n",
            "     40      133.3897  0.0916\n",
            "     41       \u001b[36m95.1074\u001b[0m  0.0851\n",
            "     42       98.4702  0.0967\n",
            "     43       \u001b[36m95.0667\u001b[0m  0.0942\n",
            "     44       \u001b[36m90.4648\u001b[0m  0.0885\n",
            "     45       \u001b[36m73.2097\u001b[0m  0.0972\n",
            "     46       74.7813  0.0931\n",
            "     47       \u001b[36m69.1728\u001b[0m  0.0973\n",
            "     48       \u001b[36m54.3325\u001b[0m  0.0932\n",
            "     49       \u001b[36m49.5492\u001b[0m  0.0985\n",
            "     50       \u001b[36m46.1526\u001b[0m  0.1085\n",
            "     51       \u001b[36m40.1990\u001b[0m  0.1007\n",
            "     52       \u001b[36m39.3243\u001b[0m  0.1014\n",
            "     53       \u001b[36m36.6995\u001b[0m  0.0883\n",
            "     54       \u001b[36m31.2501\u001b[0m  0.0925\n",
            "     55       \u001b[36m27.8222\u001b[0m  0.0919\n",
            "     56       \u001b[36m24.2310\u001b[0m  0.0967\n",
            "     57       \u001b[36m22.3949\u001b[0m  0.0961\n",
            "     58       \u001b[36m22.0661\u001b[0m  0.0953\n",
            "     59       \u001b[36m15.4392\u001b[0m  0.0903\n",
            "     60       \u001b[36m14.1227\u001b[0m  0.0944\n",
            "     61        \u001b[36m9.7769\u001b[0m  0.0942\n",
            "     62        \u001b[36m9.7263\u001b[0m  0.0880\n",
            "     63       10.0584  0.1084\n",
            "     64       10.9410  0.0928\n",
            "     65        \u001b[36m7.0880\u001b[0m  0.1031\n",
            "     66        \u001b[36m6.2900\u001b[0m  0.0948\n",
            "     67        \u001b[36m6.1546\u001b[0m  0.0898\n",
            "     68        \u001b[36m4.9668\u001b[0m  0.1052\n",
            "     69        \u001b[36m4.3209\u001b[0m  0.1165\n",
            "     70        \u001b[36m3.9533\u001b[0m  0.1598\n",
            "     71        \u001b[36m2.9313\u001b[0m  0.1767\n",
            "     72        \u001b[36m2.3643\u001b[0m  0.1374\n",
            "     73        \u001b[36m2.3369\u001b[0m  0.1299\n",
            "     74        \u001b[36m2.1497\u001b[0m  0.1363\n",
            "     75        2.8375  0.1343\n",
            "     76        2.6417  0.1373\n",
            "     77        2.1699  0.1338\n",
            "     78        2.1814  0.1427\n",
            "     79        \u001b[36m1.6955\u001b[0m  0.1466\n",
            "     80        1.9303  0.1245\n",
            "     81        \u001b[36m1.5415\u001b[0m  0.1275\n",
            "     82        \u001b[36m1.4384\u001b[0m  0.1286\n",
            "     83        \u001b[36m1.4209\u001b[0m  0.1253\n",
            "     84        \u001b[36m1.3874\u001b[0m  0.1408\n",
            "     85        \u001b[36m1.1328\u001b[0m  0.1423\n",
            "     86        1.1686  0.1408\n",
            "     87        1.3903  0.1484\n",
            "     88        1.2986  0.1346\n",
            "     89        1.6497  0.1687\n",
            "     90        1.5257  0.0881\n",
            "     91        2.0050  0.0932\n",
            "     92        \u001b[36m0.9452\u001b[0m  0.0983\n",
            "     93        0.9770  0.0848\n",
            "     94        \u001b[36m0.7738\u001b[0m  0.0854\n",
            "     95        0.8495  0.0885\n",
            "     96        1.1652  0.1062\n",
            "     97        1.0898  0.0892\n",
            "     98        1.5045  0.0900\n",
            "     99        1.0323  0.0903\n",
            "    100        1.3746  0.0925\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m35901.0116\u001b[0m  0.0893\n",
            "      2    \u001b[36m31332.4359\u001b[0m  0.0965\n",
            "      3    \u001b[36m24251.7195\u001b[0m  0.0876\n",
            "      4    \u001b[36m20079.5442\u001b[0m  0.0854\n",
            "      5    \u001b[36m14866.4442\u001b[0m  0.1005\n",
            "      6    \u001b[36m12223.2820\u001b[0m  0.0882\n",
            "      7     \u001b[36m8794.7670\u001b[0m  0.1134\n",
            "      8     \u001b[36m6453.5208\u001b[0m  0.0927\n",
            "      9     \u001b[36m5134.0690\u001b[0m  0.0893\n",
            "     10     \u001b[36m3997.5777\u001b[0m  0.0960\n",
            "     11     \u001b[36m2895.3603\u001b[0m  0.0871\n",
            "     12     \u001b[36m2676.4855\u001b[0m  0.0937\n",
            "     13     \u001b[36m2512.0289\u001b[0m  0.0954\n",
            "     14     \u001b[36m2195.8068\u001b[0m  0.0866\n",
            "     15     2340.9540  0.0868\n",
            "     16     \u001b[36m1991.2861\u001b[0m  0.0895\n",
            "     17     \u001b[36m1809.2826\u001b[0m  0.1124\n",
            "     18     1836.3997  0.1117\n",
            "     19     \u001b[36m1710.0754\u001b[0m  0.0952\n",
            "     20     \u001b[36m1373.6028\u001b[0m  0.1023\n",
            "     21     1389.7532  0.0980\n",
            "     22     \u001b[36m1119.8564\u001b[0m  0.1016\n",
            "     23     1198.9159  0.0965\n",
            "     24     1135.5337  0.1011\n",
            "     25      \u001b[36m980.9046\u001b[0m  0.0900\n",
            "     26      \u001b[36m951.2099\u001b[0m  0.0902\n",
            "     27      \u001b[36m751.0421\u001b[0m  0.1066\n",
            "     28      798.4264  0.0963\n",
            "     29      \u001b[36m728.4950\u001b[0m  0.0931\n",
            "     30      \u001b[36m532.4236\u001b[0m  0.0909\n",
            "     31      550.4503  0.0961\n",
            "     32      609.0761  0.0952\n",
            "     33      \u001b[36m424.1837\u001b[0m  0.0881\n",
            "     34      484.7227  0.0952\n",
            "     35      460.7996  0.0895\n",
            "     36      \u001b[36m365.6686\u001b[0m  0.0903\n",
            "     37      427.0263  0.0975\n",
            "     38      391.1177  0.1086\n",
            "     39      \u001b[36m321.0169\u001b[0m  0.0895\n",
            "     40      \u001b[36m268.0114\u001b[0m  0.1009\n",
            "     41      307.2670  0.1016\n",
            "     42      283.4571  0.0975\n",
            "     43      \u001b[36m223.2751\u001b[0m  0.0906\n",
            "     44      \u001b[36m215.3882\u001b[0m  0.0930\n",
            "     45      \u001b[36m156.0068\u001b[0m  0.0889\n",
            "     46      \u001b[36m149.8730\u001b[0m  0.0899\n",
            "     47      162.3305  0.1020\n",
            "     48      163.5918  0.1204\n",
            "     49      \u001b[36m146.7322\u001b[0m  0.1109\n",
            "     50      \u001b[36m127.9306\u001b[0m  0.0907\n",
            "     51      \u001b[36m108.0183\u001b[0m  0.0889\n",
            "     52      \u001b[36m103.4528\u001b[0m  0.1085\n",
            "     53      \u001b[36m102.9720\u001b[0m  0.0977\n",
            "     54       \u001b[36m92.4652\u001b[0m  0.0873\n",
            "     55       \u001b[36m85.0846\u001b[0m  0.0907\n",
            "     56       89.4058  0.0944\n",
            "     57       \u001b[36m76.8948\u001b[0m  0.1127\n",
            "     58       \u001b[36m66.6865\u001b[0m  0.0958\n",
            "     59       \u001b[36m61.7257\u001b[0m  0.0916\n",
            "     60       \u001b[36m61.1487\u001b[0m  0.0913\n",
            "     61       \u001b[36m54.4427\u001b[0m  0.0884\n",
            "     62       \u001b[36m54.0684\u001b[0m  0.0983\n",
            "     63       \u001b[36m45.5212\u001b[0m  0.0892\n",
            "     64       \u001b[36m38.5738\u001b[0m  0.0980\n",
            "     65       \u001b[36m33.8098\u001b[0m  0.0939\n",
            "     66       \u001b[36m29.0231\u001b[0m  0.0886\n",
            "     67       32.4016  0.0887\n",
            "     68       36.4915  0.0890\n",
            "     69       \u001b[36m23.3712\u001b[0m  0.1096\n",
            "     70       30.1106  0.0892\n",
            "     71       \u001b[36m21.8980\u001b[0m  0.0941\n",
            "     72       23.1214  0.0923\n",
            "     73       \u001b[36m19.6211\u001b[0m  0.0919\n",
            "     74       \u001b[36m18.5886\u001b[0m  0.0883\n",
            "     75       \u001b[36m17.6106\u001b[0m  0.0976\n",
            "     76       \u001b[36m12.7791\u001b[0m  0.0893\n",
            "     77       13.1701  0.0868\n",
            "     78       13.7568  0.1091\n",
            "     79       13.3282  0.0856\n",
            "     80       \u001b[36m11.5305\u001b[0m  0.1039\n",
            "     81       12.5284  0.0990\n",
            "     82        \u001b[36m9.1466\u001b[0m  0.0875\n",
            "     83        9.2755  0.0898\n",
            "     84        \u001b[36m6.8967\u001b[0m  0.0923\n",
            "     85        7.2210  0.0854\n",
            "     86        8.3054  0.0863\n",
            "     87        \u001b[36m6.5803\u001b[0m  0.0949\n",
            "     88        \u001b[36m5.4426\u001b[0m  0.0846\n",
            "     89        \u001b[36m4.9682\u001b[0m  0.0858\n",
            "     90        5.3524  0.0934\n",
            "     91        \u001b[36m3.5319\u001b[0m  0.1017\n",
            "     92        5.5849  0.1270\n",
            "     93        \u001b[36m3.0161\u001b[0m  0.1381\n",
            "     94        4.3089  0.1328\n",
            "     95        3.1338  0.1256\n",
            "     96        3.6029  0.1305\n",
            "     97        3.0700  0.1279\n",
            "     98        \u001b[36m2.9144\u001b[0m  0.1547\n",
            "     99        \u001b[36m2.1956\u001b[0m  0.1435\n",
            "    100        \u001b[36m1.7778\u001b[0m  0.1390\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m27227.1712\u001b[0m  0.1321\n",
            "      2    \u001b[36m23654.9703\u001b[0m  0.1277\n",
            "      3    \u001b[36m18378.7462\u001b[0m  0.1211\n",
            "      4    \u001b[36m15107.2967\u001b[0m  0.1285\n",
            "      5    \u001b[36m11899.8621\u001b[0m  0.1248\n",
            "      6     \u001b[36m9418.5937\u001b[0m  0.1581\n",
            "      7     \u001b[36m6906.3845\u001b[0m  0.1319\n",
            "      8     \u001b[36m5310.9177\u001b[0m  0.1500\n",
            "      9     \u001b[36m4056.3409\u001b[0m  0.1280\n",
            "     10     \u001b[36m2846.8200\u001b[0m  0.1251\n",
            "     11     \u001b[36m2328.7515\u001b[0m  0.1387\n",
            "     12     \u001b[36m1629.3000\u001b[0m  0.1290\n",
            "     13     \u001b[36m1188.9655\u001b[0m  0.0973\n",
            "     14     1193.6031  0.1027\n",
            "     15     \u001b[36m1036.2695\u001b[0m  0.0935\n",
            "     16      \u001b[36m849.4758\u001b[0m  0.1009\n",
            "     17      \u001b[36m838.1170\u001b[0m  0.0883\n",
            "     18      \u001b[36m792.5611\u001b[0m  0.0882\n",
            "     19      \u001b[36m745.7982\u001b[0m  0.0987\n",
            "     20      \u001b[36m623.6218\u001b[0m  0.0941\n",
            "     21      \u001b[36m540.1773\u001b[0m  0.0887\n",
            "     22      \u001b[36m539.7626\u001b[0m  0.1015\n",
            "     23      \u001b[36m466.6602\u001b[0m  0.0877\n",
            "     24      \u001b[36m430.5200\u001b[0m  0.0979\n",
            "     25      \u001b[36m389.9918\u001b[0m  0.1069\n",
            "     26      \u001b[36m374.7279\u001b[0m  0.0887\n",
            "     27      \u001b[36m335.9619\u001b[0m  0.0924\n",
            "     28      \u001b[36m304.5181\u001b[0m  0.0868\n",
            "     29      336.7119  0.0881\n",
            "     30      \u001b[36m270.5660\u001b[0m  0.0886\n",
            "     31      \u001b[36m227.2085\u001b[0m  0.0960\n",
            "     32      \u001b[36m197.9089\u001b[0m  0.0923\n",
            "     33      \u001b[36m192.0095\u001b[0m  0.0951\n",
            "     34      201.4446  0.0947\n",
            "     35      \u001b[36m153.2719\u001b[0m  0.1009\n",
            "     36      \u001b[36m141.6613\u001b[0m  0.1085\n",
            "     37      \u001b[36m122.9616\u001b[0m  0.0907\n",
            "     38      \u001b[36m110.9859\u001b[0m  0.0928\n",
            "     39      114.9652  0.0928\n",
            "     40       \u001b[36m90.5887\u001b[0m  0.1049\n",
            "     41       \u001b[36m90.5507\u001b[0m  0.0902\n",
            "     42       \u001b[36m64.6627\u001b[0m  0.0888\n",
            "     43       71.1480  0.1041\n",
            "     44       77.9626  0.0979\n",
            "     45       \u001b[36m59.2806\u001b[0m  0.0873\n",
            "     46       \u001b[36m46.6794\u001b[0m  0.1054\n",
            "     47       \u001b[36m43.8751\u001b[0m  0.0930\n",
            "     48       43.9704  0.0882\n",
            "     49       44.5932  0.0935\n",
            "     50       \u001b[36m34.0869\u001b[0m  0.0906\n",
            "     51       \u001b[36m29.7418\u001b[0m  0.0891\n",
            "     52       30.1274  0.0949\n",
            "     53       \u001b[36m25.0928\u001b[0m  0.0942\n",
            "     54       \u001b[36m23.9797\u001b[0m  0.0895\n",
            "     55       \u001b[36m20.6012\u001b[0m  0.0935\n",
            "     56       \u001b[36m16.1072\u001b[0m  0.1001\n",
            "     57       16.2668  0.0912\n",
            "     58       \u001b[36m11.3729\u001b[0m  0.0898\n",
            "     59       11.5361  0.1005\n",
            "     60       \u001b[36m11.1094\u001b[0m  0.0920\n",
            "     61        \u001b[36m8.1681\u001b[0m  0.0947\n",
            "     62        \u001b[36m6.8587\u001b[0m  0.1150\n",
            "     63        \u001b[36m6.4478\u001b[0m  0.0907\n",
            "     64        \u001b[36m3.6720\u001b[0m  0.0905\n",
            "     65        3.9300  0.0987\n",
            "     66        \u001b[36m2.8519\u001b[0m  0.0893\n",
            "     67        2.8748  0.1072\n",
            "     68        \u001b[36m2.5798\u001b[0m  0.0891\n",
            "     69        3.4258  0.0870\n",
            "     70        2.9454  0.0936\n",
            "     71        3.8035  0.0883\n",
            "     72        \u001b[36m1.2858\u001b[0m  0.0895\n",
            "     73        3.1735  0.0925\n",
            "     74        \u001b[36m1.1287\u001b[0m  0.0911\n",
            "     75        1.5674  0.0945\n",
            "     76        1.6168  0.1021\n",
            "     77        \u001b[36m1.0944\u001b[0m  0.0945\n",
            "     78        \u001b[36m0.9947\u001b[0m  0.0927\n",
            "     79        1.4280  0.0929\n",
            "     80        \u001b[36m0.8037\u001b[0m  0.0844\n",
            "     81        1.3053  0.0933\n",
            "     82        1.4398  0.0903\n",
            "     83        0.8896  0.0882\n",
            "     84        1.7705  0.0994\n",
            "     85        1.2220  0.0878\n",
            "     86        0.9429  0.0906\n",
            "     87        \u001b[36m0.7824\u001b[0m  0.0973\n",
            "     88        1.3722  0.1004\n",
            "     89        0.9805  0.0865\n",
            "     90        \u001b[36m0.6491\u001b[0m  0.0951\n",
            "     91        0.6755  0.0905\n",
            "     92        \u001b[36m0.6350\u001b[0m  0.0918\n",
            "     93        1.0172  0.1033\n",
            "     94        0.7100  0.0897\n",
            "     95        1.3014  0.0884\n",
            "     96        \u001b[36m0.5356\u001b[0m  0.0987\n",
            "     97        0.5875  0.0984\n",
            "     98        0.6307  0.0908\n",
            "     99        0.5930  0.1053\n",
            "    100        \u001b[36m0.5104\u001b[0m  0.0884\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m26745.7537\u001b[0m  0.0896\n",
            "      2    \u001b[36m20882.2561\u001b[0m  0.0996\n",
            "      3    \u001b[36m15902.8362\u001b[0m  0.0992\n",
            "      4    \u001b[36m12206.2197\u001b[0m  0.0921\n",
            "      5     \u001b[36m9858.7196\u001b[0m  0.0965\n",
            "      6     \u001b[36m7002.1339\u001b[0m  0.0883\n",
            "      7     \u001b[36m4967.4002\u001b[0m  0.0951\n",
            "      8     \u001b[36m3912.7311\u001b[0m  0.0888\n",
            "      9     \u001b[36m2479.1829\u001b[0m  0.1025\n",
            "     10     \u001b[36m2185.2226\u001b[0m  0.1015\n",
            "     11     \u001b[36m1418.2106\u001b[0m  0.0881\n",
            "     12     \u001b[36m1397.9210\u001b[0m  0.0900\n",
            "     13     1455.4627  0.0976\n",
            "     14     \u001b[36m1206.8370\u001b[0m  0.0886\n",
            "     15     1216.3338  0.1273\n",
            "     16     \u001b[36m1047.2385\u001b[0m  0.1351\n",
            "     17     1223.5428  0.1543\n",
            "     18      \u001b[36m786.9263\u001b[0m  0.1454\n",
            "     19      \u001b[36m658.2817\u001b[0m  0.1387\n",
            "     20      878.2766  0.1283\n",
            "     21      695.2355  0.1499\n",
            "     22      \u001b[36m591.8574\u001b[0m  0.1277\n",
            "     23      652.7092  0.1259\n",
            "     24      612.1212  0.1301\n",
            "     25      \u001b[36m471.0019\u001b[0m  0.1278\n",
            "     26      494.4439  0.1345\n",
            "     27      \u001b[36m421.7775\u001b[0m  0.1224\n",
            "     28      \u001b[36m385.4246\u001b[0m  0.1320\n",
            "     29      \u001b[36m320.7348\u001b[0m  0.1192\n",
            "     30      327.9229  0.1214\n",
            "     31      \u001b[36m311.3152\u001b[0m  0.1358\n",
            "     32      \u001b[36m260.2005\u001b[0m  0.1377\n",
            "     33      \u001b[36m230.7443\u001b[0m  0.1272\n",
            "     34      \u001b[36m208.1162\u001b[0m  0.1353\n",
            "     35      \u001b[36m181.2374\u001b[0m  0.1289\n",
            "     36      \u001b[36m154.6797\u001b[0m  0.1345\n",
            "     37      158.7298  0.1197\n",
            "     38      165.6466  0.0887\n",
            "     39      \u001b[36m124.7955\u001b[0m  0.0936\n",
            "     40      126.8770  0.0935\n",
            "     41      \u001b[36m104.5909\u001b[0m  0.0863\n",
            "     42      \u001b[36m103.5370\u001b[0m  0.0890\n",
            "     43      104.5325  0.0902\n",
            "     44       \u001b[36m69.2817\u001b[0m  0.0969\n",
            "     45       76.6105  0.0899\n",
            "     46       \u001b[36m60.9111\u001b[0m  0.0951\n",
            "     47       67.5807  0.0855\n",
            "     48       \u001b[36m52.3938\u001b[0m  0.0956\n",
            "     49       53.2064  0.0898\n",
            "     50       \u001b[36m40.8367\u001b[0m  0.0937\n",
            "     51       \u001b[36m37.2482\u001b[0m  0.0911\n",
            "     52       \u001b[36m35.2404\u001b[0m  0.0872\n",
            "     53       \u001b[36m31.6094\u001b[0m  0.0960\n",
            "     54       32.2103  0.1009\n",
            "     55       \u001b[36m23.3676\u001b[0m  0.0990\n",
            "     56       \u001b[36m22.7737\u001b[0m  0.1147\n",
            "     57       \u001b[36m22.0409\u001b[0m  0.1001\n",
            "     58       \u001b[36m16.2528\u001b[0m  0.1008\n",
            "     59       \u001b[36m14.6165\u001b[0m  0.0928\n",
            "     60       15.2563  0.1001\n",
            "     61        \u001b[36m9.9570\u001b[0m  0.0957\n",
            "     62        \u001b[36m9.2991\u001b[0m  0.0948\n",
            "     63        9.5163  0.0951\n",
            "     64        \u001b[36m5.9882\u001b[0m  0.1021\n",
            "     65        6.3571  0.0890\n",
            "     66        \u001b[36m4.2607\u001b[0m  0.0990\n",
            "     67        4.4557  0.0900\n",
            "     68        \u001b[36m4.0055\u001b[0m  0.0900\n",
            "     69        \u001b[36m2.6954\u001b[0m  0.0905\n",
            "     70        \u001b[36m1.9179\u001b[0m  0.0934\n",
            "     71        \u001b[36m1.4083\u001b[0m  0.0923\n",
            "     72        1.8453  0.0979\n",
            "     73        1.4768  0.0880\n",
            "     74        \u001b[36m1.1415\u001b[0m  0.0936\n",
            "     75        1.9221  0.1064\n",
            "     76        2.2315  0.0879\n",
            "     77        \u001b[36m0.9059\u001b[0m  0.0969\n",
            "     78        2.5554  0.0965\n",
            "     79        \u001b[36m0.8692\u001b[0m  0.0909\n",
            "     80        1.2191  0.0909\n",
            "     81        0.9362  0.0946\n",
            "     82        0.9005  0.0866\n",
            "     83        \u001b[36m0.8522\u001b[0m  0.0885\n",
            "     84        1.7098  0.0944\n",
            "     85        1.2211  0.0907\n",
            "     86        \u001b[36m0.7680\u001b[0m  0.1026\n",
            "     87        \u001b[36m0.5397\u001b[0m  0.0945\n",
            "     88        1.0005  0.0867\n",
            "     89        0.8120  0.0872\n",
            "     90        1.0071  0.0896\n",
            "     91        0.6419  0.0956\n",
            "     92        1.1730  0.0922\n",
            "     93        0.6617  0.0891\n",
            "     94        0.7423  0.0967\n",
            "     95        0.7441  0.0882\n",
            "     96        0.6486  0.0904\n",
            "     97        0.8897  0.1111\n",
            "     98        0.6835  0.0867\n",
            "     99        1.2083  0.0942\n",
            "    100        0.5640  0.0910\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m41281.4042\u001b[0m  0.0867\n",
            "      2    \u001b[36m34890.7419\u001b[0m  0.0891\n",
            "      3    \u001b[36m28364.1254\u001b[0m  0.0921\n",
            "      4    \u001b[36m22619.1189\u001b[0m  0.0938\n",
            "      5    \u001b[36m18520.1011\u001b[0m  0.0904\n",
            "      6    \u001b[36m15172.5660\u001b[0m  0.0968\n",
            "      7    \u001b[36m12721.4099\u001b[0m  0.0973\n",
            "      8     \u001b[36m9625.3141\u001b[0m  0.1014\n",
            "      9     \u001b[36m7883.3375\u001b[0m  0.0965\n",
            "     10     \u001b[36m5698.7306\u001b[0m  0.0907\n",
            "     11     \u001b[36m4759.0953\u001b[0m  0.0927\n",
            "     12     \u001b[36m3027.8998\u001b[0m  0.0972\n",
            "     13     \u001b[36m2905.0264\u001b[0m  0.0860\n",
            "     14     \u001b[36m2198.0544\u001b[0m  0.0912\n",
            "     15     \u001b[36m1795.4005\u001b[0m  0.0972\n",
            "     16     \u001b[36m1759.4751\u001b[0m  0.0923\n",
            "     17     1772.5320  0.1004\n",
            "     18     \u001b[36m1308.9884\u001b[0m  0.1095\n",
            "     19     1420.4524  0.0842\n",
            "     20     \u001b[36m1150.8604\u001b[0m  0.0863\n",
            "     21     1229.1702  0.0882\n",
            "     22     \u001b[36m1118.8911\u001b[0m  0.0984\n",
            "     23     \u001b[36m1023.8136\u001b[0m  0.0870\n",
            "     24     1069.6330  0.0871\n",
            "     25      \u001b[36m889.3069\u001b[0m  0.0905\n",
            "     26      \u001b[36m806.5320\u001b[0m  0.0907\n",
            "     27      808.0056  0.0913\n",
            "     28      \u001b[36m679.4669\u001b[0m  0.0932\n",
            "     29      \u001b[36m650.5808\u001b[0m  0.0984\n",
            "     30      \u001b[36m480.3698\u001b[0m  0.0944\n",
            "     31      503.8882  0.0890\n",
            "     32      488.0364  0.0955\n",
            "     33      \u001b[36m468.9557\u001b[0m  0.0887\n",
            "     34      \u001b[36m415.4547\u001b[0m  0.0853\n",
            "     35      \u001b[36m371.7146\u001b[0m  0.0924\n",
            "     36      378.5333  0.0860\n",
            "     37      \u001b[36m336.4224\u001b[0m  0.0914\n",
            "     38      \u001b[36m308.8141\u001b[0m  0.0947\n",
            "     39      \u001b[36m273.4030\u001b[0m  0.1152\n",
            "     40      \u001b[36m239.4732\u001b[0m  0.1192\n",
            "     41      \u001b[36m226.4476\u001b[0m  0.1508\n",
            "     42      231.7759  0.1397\n",
            "     43      \u001b[36m190.9457\u001b[0m  0.1239\n",
            "     44      \u001b[36m171.9952\u001b[0m  0.1254\n",
            "     45      \u001b[36m164.6986\u001b[0m  0.1234\n",
            "     46      \u001b[36m142.1976\u001b[0m  0.1297\n",
            "     47      149.5990  0.1528\n",
            "     48      \u001b[36m134.0419\u001b[0m  0.1244\n",
            "     49      \u001b[36m129.0141\u001b[0m  0.1301\n",
            "     50      \u001b[36m109.1505\u001b[0m  0.1367\n",
            "     51      114.7929  0.1304\n",
            "     52      \u001b[36m108.2233\u001b[0m  0.1249\n",
            "     53       \u001b[36m92.6103\u001b[0m  0.1402\n",
            "     54       99.9914  0.1205\n",
            "     55       \u001b[36m79.2959\u001b[0m  0.1557\n",
            "     56       80.7234  0.1292\n",
            "     57       \u001b[36m74.9858\u001b[0m  0.1748\n",
            "     58       \u001b[36m66.6784\u001b[0m  0.1325\n",
            "     59       \u001b[36m54.2509\u001b[0m  0.1483\n",
            "     60       60.4510  0.1436\n",
            "     61       \u001b[36m49.0995\u001b[0m  0.1257\n",
            "     62       \u001b[36m48.9315\u001b[0m  0.0960\n",
            "     63       51.4305  0.0887\n",
            "     64       \u001b[36m43.1180\u001b[0m  0.0890\n",
            "     65       \u001b[36m42.3555\u001b[0m  0.0896\n",
            "     66       \u001b[36m37.5590\u001b[0m  0.0934\n",
            "     67       \u001b[36m30.8961\u001b[0m  0.0886\n",
            "     68       39.9201  0.0868\n",
            "     69       \u001b[36m25.5293\u001b[0m  0.0994\n",
            "     70       \u001b[36m23.0647\u001b[0m  0.0926\n",
            "     71       24.4241  0.0888\n",
            "     72       \u001b[36m18.8785\u001b[0m  0.0860\n",
            "     73       21.5241  0.0983\n",
            "     74       21.4895  0.0901\n",
            "     75       \u001b[36m16.8187\u001b[0m  0.0901\n",
            "     76       18.2543  0.0933\n",
            "     77       \u001b[36m14.4592\u001b[0m  0.0852\n",
            "     78       \u001b[36m13.0347\u001b[0m  0.0894\n",
            "     79       \u001b[36m12.4763\u001b[0m  0.0965\n",
            "     80       12.7995  0.1021\n",
            "     81        \u001b[36m8.7310\u001b[0m  0.0905\n",
            "     82       11.2959  0.0886\n",
            "     83        9.6943  0.0954\n",
            "     84        \u001b[36m7.5277\u001b[0m  0.0988\n",
            "     85        7.7536  0.0915\n",
            "     86        \u001b[36m5.7037\u001b[0m  0.0988\n",
            "     87        \u001b[36m5.6216\u001b[0m  0.0872\n",
            "     88        6.5774  0.0933\n",
            "     89        \u001b[36m5.4704\u001b[0m  0.0994\n",
            "     90        5.5192  0.0899\n",
            "     91        \u001b[36m3.2707\u001b[0m  0.0899\n",
            "     92        3.9531  0.0931\n",
            "     93        3.6030  0.0895\n",
            "     94        \u001b[36m2.8577\u001b[0m  0.0908\n",
            "     95        3.9351  0.0991\n",
            "     96        3.5560  0.0891\n",
            "     97        4.0082  0.0878\n",
            "     98        3.7025  0.0935\n",
            "     99        4.1248  0.0870\n",
            "    100        \u001b[36m2.5616\u001b[0m  0.0883\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m31357.1241\u001b[0m  0.0893\n",
            "      2    \u001b[36m24098.1737\u001b[0m  0.0904\n",
            "      3    \u001b[36m20999.7311\u001b[0m  0.0847\n",
            "      4    \u001b[36m16476.9687\u001b[0m  0.0944\n",
            "      5    \u001b[36m12939.3575\u001b[0m  0.0923\n",
            "      6    \u001b[36m11159.0811\u001b[0m  0.1028\n",
            "      7     \u001b[36m8002.5155\u001b[0m  0.1048\n",
            "      8     \u001b[36m6733.1594\u001b[0m  0.0878\n",
            "      9     \u001b[36m5514.4473\u001b[0m  0.0875\n",
            "     10     \u001b[36m4100.2998\u001b[0m  0.0927\n",
            "     11     \u001b[36m3306.4120\u001b[0m  0.0915\n",
            "     12     \u001b[36m2470.2151\u001b[0m  0.0961\n",
            "     13     \u001b[36m1854.2006\u001b[0m  0.0966\n",
            "     14     \u001b[36m1309.4619\u001b[0m  0.0886\n",
            "     15      \u001b[36m949.8972\u001b[0m  0.0895\n",
            "     16      \u001b[36m862.0931\u001b[0m  0.1067\n",
            "     17      \u001b[36m786.7918\u001b[0m  0.0955\n",
            "     18      \u001b[36m621.5412\u001b[0m  0.0912\n",
            "     19      632.5088  0.1018\n",
            "     20      \u001b[36m515.2287\u001b[0m  0.0971\n",
            "     21      560.1965  0.0921\n",
            "     22      \u001b[36m454.5510\u001b[0m  0.0920\n",
            "     23      \u001b[36m381.6086\u001b[0m  0.0965\n",
            "     24      \u001b[36m362.0389\u001b[0m  0.0929\n",
            "     25      370.9429  0.0948\n",
            "     26      \u001b[36m318.0743\u001b[0m  0.1667\n",
            "     27      \u001b[36m296.0973\u001b[0m  0.1383\n",
            "     28      \u001b[36m277.9240\u001b[0m  0.1329\n",
            "     29      \u001b[36m194.7072\u001b[0m  0.1376\n",
            "     30      212.0513  0.1357\n",
            "     31      232.2921  0.1293\n",
            "     32      \u001b[36m182.1476\u001b[0m  0.1239\n",
            "     33      205.6603  0.1302\n",
            "     34      \u001b[36m176.6991\u001b[0m  0.1663\n",
            "     35      \u001b[36m144.6075\u001b[0m  0.1359\n",
            "     36      144.8642  0.1192\n",
            "     37      \u001b[36m138.7524\u001b[0m  0.1323\n",
            "     38      146.4561  0.1208\n",
            "     39      \u001b[36m133.3742\u001b[0m  0.1263\n",
            "     40       \u001b[36m99.1667\u001b[0m  0.1323\n",
            "     41       \u001b[36m91.4869\u001b[0m  0.1262\n",
            "     42       93.4978  0.1435\n",
            "     43       \u001b[36m79.4542\u001b[0m  0.1313\n",
            "     44       \u001b[36m76.4291\u001b[0m  0.1375\n",
            "     45       \u001b[36m66.7397\u001b[0m  0.1357\n",
            "     46       70.4594  0.1676\n",
            "     47       \u001b[36m65.1411\u001b[0m  0.1150\n",
            "     48       \u001b[36m59.6456\u001b[0m  0.0894\n",
            "     49       \u001b[36m43.3957\u001b[0m  0.0968\n",
            "     50       \u001b[36m40.6519\u001b[0m  0.1078\n",
            "     51       \u001b[36m38.8160\u001b[0m  0.0943\n",
            "     52       \u001b[36m36.5609\u001b[0m  0.0895\n",
            "     53       \u001b[36m34.4387\u001b[0m  0.0910\n",
            "     54       \u001b[36m31.9331\u001b[0m  0.1142\n",
            "     55       \u001b[36m27.8065\u001b[0m  0.1240\n",
            "     56       30.2164  0.1307\n",
            "     57       \u001b[36m21.2500\u001b[0m  0.1343\n",
            "     58       24.1606  0.1389\n",
            "     59       \u001b[36m18.2684\u001b[0m  0.1575\n",
            "     60       19.9646  0.1304\n",
            "     61       \u001b[36m15.3904\u001b[0m  0.1281\n",
            "     62       18.4442  0.1313\n",
            "     63       \u001b[36m12.0139\u001b[0m  0.1231\n",
            "     64       \u001b[36m11.5563\u001b[0m  0.1313\n",
            "     65       12.1468  0.1233\n",
            "     66       \u001b[36m10.0275\u001b[0m  0.1234\n",
            "     67        \u001b[36m8.2153\u001b[0m  0.1399\n",
            "     68       10.2752  0.1333\n",
            "     69       12.0423  0.1253\n",
            "     70       10.1270  0.1282\n",
            "     71        \u001b[36m8.0273\u001b[0m  0.1434\n",
            "     72        8.8956  0.1427\n",
            "     73        \u001b[36m6.1364\u001b[0m  0.1372\n",
            "     74        6.6090  0.1399\n",
            "     75        6.4200  0.1469\n",
            "     76        6.3645  0.1039\n",
            "     77        \u001b[36m5.0528\u001b[0m  0.0945\n",
            "     78        5.4124  0.0862\n",
            "     79        6.3460  0.0928\n",
            "     80        \u001b[36m3.0599\u001b[0m  0.0973\n",
            "     81        3.0934  0.0907\n",
            "     82        3.9021  0.0881\n",
            "     83        4.2813  0.0895\n",
            "     84        \u001b[36m2.6791\u001b[0m  0.0999\n",
            "     85        4.1288  0.0919\n",
            "     86        2.7397  0.0920\n",
            "     87        \u001b[36m2.5438\u001b[0m  0.0949\n",
            "     88        \u001b[36m2.1966\u001b[0m  0.0933\n",
            "     89        3.4934  0.0932\n",
            "     90        \u001b[36m2.1509\u001b[0m  0.1051\n",
            "     91        2.4958  0.0909\n",
            "     92        \u001b[36m1.9301\u001b[0m  0.0934\n",
            "     93        2.5824  0.0933\n",
            "     94        1.9997  0.0911\n",
            "     95        \u001b[36m1.5420\u001b[0m  0.1055\n",
            "     96        1.6335  0.1008\n",
            "     97        2.2040  0.1244\n",
            "     98        1.6020  0.0920\n",
            "     99        1.8575  0.0927\n",
            "    100        \u001b[36m1.4816\u001b[0m  0.0985\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m24818.8620\u001b[0m  0.0908\n",
            "      2    \u001b[36m20807.9032\u001b[0m  0.0901\n",
            "      3    \u001b[36m16484.4522\u001b[0m  0.0969\n",
            "      4    \u001b[36m12966.4175\u001b[0m  0.0903\n",
            "      5    \u001b[36m10338.0556\u001b[0m  0.0994\n",
            "      6     \u001b[36m7673.1569\u001b[0m  0.0950\n",
            "      7     \u001b[36m6028.0364\u001b[0m  0.0893\n",
            "      8     \u001b[36m4844.5342\u001b[0m  0.1042\n",
            "      9     \u001b[36m3204.2920\u001b[0m  0.0907\n",
            "     10     \u001b[36m2406.3180\u001b[0m  0.0950\n",
            "     11     \u001b[36m1959.8183\u001b[0m  0.0966\n",
            "     12     \u001b[36m1832.5459\u001b[0m  0.0896\n",
            "     13     \u001b[36m1427.0253\u001b[0m  0.0965\n",
            "     14     1491.8196  0.1084\n",
            "     15     \u001b[36m1246.0597\u001b[0m  0.1151\n",
            "     16     1485.5282  0.1094\n",
            "     17     \u001b[36m1152.5378\u001b[0m  0.0991\n",
            "     18     \u001b[36m1034.0361\u001b[0m  0.0874\n",
            "     19      \u001b[36m963.2179\u001b[0m  0.0875\n",
            "     20      \u001b[36m885.1249\u001b[0m  0.0874\n",
            "     21      974.2581  0.0924\n",
            "     22      \u001b[36m716.5253\u001b[0m  0.0893\n",
            "     23      \u001b[36m647.9285\u001b[0m  0.0915\n",
            "     24      \u001b[36m612.3526\u001b[0m  0.0954\n",
            "     25      617.8714  0.1028\n",
            "     26      \u001b[36m564.9743\u001b[0m  0.0970\n",
            "     27      \u001b[36m466.7697\u001b[0m  0.0915\n",
            "     28      473.4866  0.0873\n",
            "     29      \u001b[36m371.5280\u001b[0m  0.0867\n",
            "     30      \u001b[36m368.3957\u001b[0m  0.0926\n",
            "     31      \u001b[36m352.3398\u001b[0m  0.1000\n",
            "     32      \u001b[36m302.9147\u001b[0m  0.0884\n",
            "     33      323.0652  0.1069\n",
            "     34      \u001b[36m238.1273\u001b[0m  0.1043\n",
            "     35      240.8593  0.0941\n",
            "     36      \u001b[36m187.3636\u001b[0m  0.1030\n",
            "     37      \u001b[36m173.3832\u001b[0m  0.1007\n",
            "     38      \u001b[36m165.2838\u001b[0m  0.0898\n",
            "     39      \u001b[36m137.8889\u001b[0m  0.0951\n",
            "     40      \u001b[36m130.9931\u001b[0m  0.0930\n",
            "     41      \u001b[36m127.0926\u001b[0m  0.0954\n",
            "     42      \u001b[36m111.6626\u001b[0m  0.0901\n",
            "     43      \u001b[36m105.4554\u001b[0m  0.0888\n",
            "     44       \u001b[36m79.1518\u001b[0m  0.1001\n",
            "     45       \u001b[36m57.0369\u001b[0m  0.0914\n",
            "     46       \u001b[36m53.8307\u001b[0m  0.0955\n",
            "     47       \u001b[36m53.3727\u001b[0m  0.1074\n",
            "     48       \u001b[36m36.8385\u001b[0m  0.0883\n",
            "     49       44.2556  0.0898\n",
            "     50       40.2127  0.1022\n",
            "     51       \u001b[36m33.3661\u001b[0m  0.0969\n",
            "     52       41.1046  0.0890\n",
            "     53       \u001b[36m27.5410\u001b[0m  0.0917\n",
            "     54       33.2330  0.0990\n",
            "     55       29.8613  0.0999\n",
            "     56       \u001b[36m24.1338\u001b[0m  0.0907\n",
            "     57       \u001b[36m20.7083\u001b[0m  0.1142\n",
            "     58       \u001b[36m14.0669\u001b[0m  0.1003\n",
            "     59       \u001b[36m12.8509\u001b[0m  0.1029\n",
            "     60       \u001b[36m12.8178\u001b[0m  0.0995\n",
            "     61       13.4576  0.0862\n",
            "     62        \u001b[36m9.9361\u001b[0m  0.1036\n",
            "     63        \u001b[36m6.3904\u001b[0m  0.0993\n",
            "     64        6.7458  0.0907\n",
            "     65        \u001b[36m4.1769\u001b[0m  0.0980\n",
            "     66        \u001b[36m2.8102\u001b[0m  0.0978\n",
            "     67        \u001b[36m2.5061\u001b[0m  0.1170\n",
            "     68        \u001b[36m1.5846\u001b[0m  0.0924\n",
            "     69        \u001b[36m1.4981\u001b[0m  0.0919\n",
            "     70        \u001b[36m1.1533\u001b[0m  0.1015\n",
            "     71        2.2913  0.1016\n",
            "     72        \u001b[36m0.9183\u001b[0m  0.1058\n",
            "     73        1.1343  0.0959\n",
            "     74        1.2288  0.1081\n",
            "     75        \u001b[36m0.8753\u001b[0m  0.1203\n",
            "     76        1.0573  0.1527\n",
            "     77        1.1466  0.1344\n",
            "     78        \u001b[36m0.7108\u001b[0m  0.1420\n",
            "     79        1.1990  0.1440\n",
            "     80        1.1012  0.1376\n",
            "     81        1.0875  0.1429\n",
            "     82        1.1463  0.1575\n",
            "     83        1.2145  0.1723\n",
            "     84        0.7920  0.1551\n",
            "     85        0.9287  0.1574\n",
            "     86        1.2510  0.1553\n",
            "     87        1.2380  0.1551\n",
            "     88        1.0330  0.1678\n",
            "     89        0.7776  0.1426\n",
            "     90        \u001b[36m0.6929\u001b[0m  0.1672\n",
            "     91        \u001b[36m0.6429\u001b[0m  0.1389\n",
            "     92        0.7807  0.1493\n",
            "     93        1.2182  0.1535\n",
            "     94        0.7731  0.1032\n",
            "     95        0.7562  0.1094\n",
            "     96        \u001b[36m0.6292\u001b[0m  0.0954\n",
            "     97        0.9651  0.0967\n",
            "     98        1.1698  0.0987\n",
            "     99        \u001b[36m0.5981\u001b[0m  0.0946\n",
            "    100        1.9871  0.0923\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m32813.3401\u001b[0m  0.0913\n",
            "      2    \u001b[36m25241.2301\u001b[0m  0.0908\n",
            "      3    \u001b[36m20878.9263\u001b[0m  0.0990\n",
            "      4    \u001b[36m17147.0572\u001b[0m  0.1027\n",
            "      5    \u001b[36m13110.2285\u001b[0m  0.0983\n",
            "      6    \u001b[36m10280.5545\u001b[0m  0.1163\n",
            "      7     \u001b[36m9424.5122\u001b[0m  0.0989\n",
            "      8     \u001b[36m7812.6906\u001b[0m  0.1153\n",
            "      9     \u001b[36m6168.2379\u001b[0m  0.0936\n",
            "     10     \u001b[36m5016.6618\u001b[0m  0.0946\n",
            "     11     \u001b[36m3594.3450\u001b[0m  0.1139\n",
            "     12     \u001b[36m2989.6981\u001b[0m  0.1041\n",
            "     13     \u001b[36m2141.6995\u001b[0m  0.0965\n",
            "     14     \u001b[36m1753.2279\u001b[0m  0.0992\n",
            "     15     \u001b[36m1328.1321\u001b[0m  0.0953\n",
            "     16     \u001b[36m1137.9133\u001b[0m  0.0955\n",
            "     17     \u001b[36m1112.8112\u001b[0m  0.1038\n",
            "     18      \u001b[36m915.2094\u001b[0m  0.1249\n",
            "     19      \u001b[36m841.2111\u001b[0m  0.1028\n",
            "     20      856.6854  0.0917\n",
            "     21      \u001b[36m729.2670\u001b[0m  0.1279\n",
            "     22      \u001b[36m626.8206\u001b[0m  0.1073\n",
            "     23      \u001b[36m573.5130\u001b[0m  0.0966\n",
            "     24      \u001b[36m511.5862\u001b[0m  0.0966\n",
            "     25      \u001b[36m429.9025\u001b[0m  0.0930\n",
            "     26      \u001b[36m418.0041\u001b[0m  0.0893\n",
            "     27      \u001b[36m360.1057\u001b[0m  0.1141\n",
            "     28      \u001b[36m339.1294\u001b[0m  0.1015\n",
            "     29      \u001b[36m323.6963\u001b[0m  0.0995\n",
            "     30      \u001b[36m316.2026\u001b[0m  0.0995\n",
            "     31      \u001b[36m258.4636\u001b[0m  0.0988\n",
            "     32      \u001b[36m198.7527\u001b[0m  0.0903\n",
            "     33      208.0754  0.1050\n",
            "     34      199.0128  0.0980\n",
            "     35      \u001b[36m181.8576\u001b[0m  0.1037\n",
            "     36      \u001b[36m164.7931\u001b[0m  0.0989\n",
            "     37      \u001b[36m163.0601\u001b[0m  0.0938\n",
            "     38      \u001b[36m135.4864\u001b[0m  0.1007\n",
            "     39      \u001b[36m127.4497\u001b[0m  0.0915\n",
            "     40      \u001b[36m104.9867\u001b[0m  0.0956\n",
            "     41      117.6774  0.1027\n",
            "     42       \u001b[36m94.8347\u001b[0m  0.0928\n",
            "     43       \u001b[36m89.0708\u001b[0m  0.0920\n",
            "     44       90.5200  0.0905\n",
            "     45       \u001b[36m76.1605\u001b[0m  0.0995\n",
            "     46       \u001b[36m66.3691\u001b[0m  0.0978\n",
            "     47       74.3384  0.1032\n",
            "     48       \u001b[36m56.7439\u001b[0m  0.1020\n",
            "     49       64.0131  0.0885\n",
            "     50       60.1678  0.0932\n",
            "     51       \u001b[36m54.7005\u001b[0m  0.1018\n",
            "     52       \u001b[36m50.7206\u001b[0m  0.0945\n",
            "     53       \u001b[36m45.2601\u001b[0m  0.0987\n",
            "     54       \u001b[36m42.6542\u001b[0m  0.0949\n",
            "     55       46.2554  0.0908\n",
            "     56       \u001b[36m34.8789\u001b[0m  0.0895\n",
            "     57       38.1937  0.0958\n",
            "     58       \u001b[36m34.0454\u001b[0m  0.0973\n",
            "     59       \u001b[36m32.0855\u001b[0m  0.1234\n",
            "     60       \u001b[36m30.8355\u001b[0m  0.1265\n",
            "     61       \u001b[36m27.0617\u001b[0m  0.1111\n",
            "     62       \u001b[36m26.7784\u001b[0m  0.1052\n",
            "     63       \u001b[36m22.1992\u001b[0m  0.1000\n",
            "     64       \u001b[36m21.4789\u001b[0m  0.0959\n",
            "     65       \u001b[36m16.4636\u001b[0m  0.1110\n",
            "     66       22.9855  0.0974\n",
            "     67       \u001b[36m14.9239\u001b[0m  0.1213\n",
            "     68       18.4581  0.1063\n",
            "     69       18.2379  0.1052\n",
            "     70       18.0468  0.1101\n",
            "     71       \u001b[36m14.5722\u001b[0m  0.0874\n",
            "     72       14.9828  0.0941\n",
            "     73       \u001b[36m12.8735\u001b[0m  0.0977\n",
            "     74       \u001b[36m10.8579\u001b[0m  0.0918\n",
            "     75       \u001b[36m10.6397\u001b[0m  0.0994\n",
            "     76       11.0926  0.1037\n",
            "     77       10.6492  0.0984\n",
            "     78        \u001b[36m8.2315\u001b[0m  0.1049\n",
            "     79        \u001b[36m7.9804\u001b[0m  0.0915\n",
            "     80        \u001b[36m7.3140\u001b[0m  0.1082\n",
            "     81        \u001b[36m7.1436\u001b[0m  0.0959\n",
            "     82        \u001b[36m5.4627\u001b[0m  0.0889\n",
            "     83        6.4104  0.1140\n",
            "     84        \u001b[36m5.2769\u001b[0m  0.1006\n",
            "     85        \u001b[36m5.0061\u001b[0m  0.1089\n",
            "     86        \u001b[36m4.5972\u001b[0m  0.0978\n",
            "     87        4.7859  0.1167\n",
            "     88        \u001b[36m3.7544\u001b[0m  0.1004\n",
            "     89        4.2591  0.0932\n",
            "     90        3.9063  0.1611\n",
            "     91        \u001b[36m3.7455\u001b[0m  0.1864\n",
            "     92        \u001b[36m2.7951\u001b[0m  0.1505\n",
            "     93        \u001b[36m2.4533\u001b[0m  0.1407\n",
            "     94        2.6098  0.1335\n",
            "     95        \u001b[36m2.0040\u001b[0m  0.1452\n",
            "     96        2.2247  0.1527\n",
            "     97        2.3960  0.1484\n",
            "     98        2.1235  0.1486\n",
            "     99        \u001b[36m1.5300\u001b[0m  0.1513\n",
            "    100        \u001b[36m1.4053\u001b[0m  0.1439\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m27917.4961\u001b[0m  0.1349\n",
            "      2    \u001b[36m22835.1506\u001b[0m  0.1733\n",
            "      3    \u001b[36m16528.7937\u001b[0m  0.1266\n",
            "      4    \u001b[36m13972.2686\u001b[0m  0.1421\n",
            "      5    \u001b[36m10043.1907\u001b[0m  0.1281\n",
            "      6     \u001b[36m7579.0189\u001b[0m  0.1406\n",
            "      7     \u001b[36m5072.0798\u001b[0m  0.1335\n",
            "      8     \u001b[36m4084.9211\u001b[0m  0.1336\n",
            "      9     \u001b[36m2594.5854\u001b[0m  0.1198\n",
            "     10     \u001b[36m2234.2925\u001b[0m  0.1067\n",
            "     11     \u001b[36m2055.2793\u001b[0m  0.1138\n",
            "     12     \u001b[36m1760.3207\u001b[0m  0.1025\n",
            "     13     \u001b[36m1742.2072\u001b[0m  0.0931\n",
            "     14     \u001b[36m1595.7518\u001b[0m  0.0929\n",
            "     15     \u001b[36m1406.2514\u001b[0m  0.1048\n",
            "     16     \u001b[36m1384.4118\u001b[0m  0.0897\n",
            "     17     \u001b[36m1190.4568\u001b[0m  0.0901\n",
            "     18      \u001b[36m977.8883\u001b[0m  0.1057\n",
            "     19     1008.2847  0.1226\n",
            "     20      \u001b[36m939.3145\u001b[0m  0.0951\n",
            "     21      \u001b[36m823.0164\u001b[0m  0.1015\n",
            "     22      \u001b[36m709.9990\u001b[0m  0.0913\n",
            "     23      \u001b[36m634.3033\u001b[0m  0.0954\n",
            "     24      \u001b[36m600.3872\u001b[0m  0.0882\n",
            "     25      \u001b[36m506.3047\u001b[0m  0.0951\n",
            "     26      \u001b[36m433.3342\u001b[0m  0.1117\n",
            "     27      440.1961  0.0961\n",
            "     28      \u001b[36m329.2132\u001b[0m  0.1011\n",
            "     29      \u001b[36m295.5495\u001b[0m  0.1186\n",
            "     30      301.6490  0.1005\n",
            "     31      \u001b[36m254.8208\u001b[0m  0.0869\n",
            "     32      \u001b[36m233.1787\u001b[0m  0.0926\n",
            "     33      \u001b[36m211.5451\u001b[0m  0.0902\n",
            "     34      \u001b[36m185.1217\u001b[0m  0.0844\n",
            "     35      \u001b[36m164.5706\u001b[0m  0.0971\n",
            "     36      \u001b[36m164.1556\u001b[0m  0.1078\n",
            "     37      \u001b[36m136.3126\u001b[0m  0.0899\n",
            "     38      \u001b[36m102.6259\u001b[0m  0.0870\n",
            "     39      \u001b[36m101.4013\u001b[0m  0.1002\n",
            "     40       \u001b[36m74.8888\u001b[0m  0.0916\n",
            "     41       \u001b[36m59.6209\u001b[0m  0.1084\n",
            "     42       \u001b[36m59.3406\u001b[0m  0.0930\n",
            "     43       \u001b[36m53.1225\u001b[0m  0.0881\n",
            "     44       \u001b[36m48.9008\u001b[0m  0.1012\n",
            "     45       \u001b[36m37.0017\u001b[0m  0.0947\n",
            "     46       \u001b[36m30.8995\u001b[0m  0.0910\n",
            "     47       37.0230  0.1005\n",
            "     48       34.8317  0.1110\n",
            "     49       \u001b[36m23.7023\u001b[0m  0.0954\n",
            "     50       \u001b[36m19.8729\u001b[0m  0.1127\n",
            "     51       \u001b[36m16.9484\u001b[0m  0.0918\n",
            "     52       21.4618  0.0864\n",
            "     53       \u001b[36m15.6081\u001b[0m  0.0864\n",
            "     54       \u001b[36m11.8325\u001b[0m  0.0885\n",
            "     55       16.2753  0.0907\n",
            "     56        \u001b[36m8.9104\u001b[0m  0.0893\n",
            "     57        \u001b[36m7.2513\u001b[0m  0.0883\n",
            "     58        \u001b[36m6.9177\u001b[0m  0.0916\n",
            "     59        \u001b[36m4.2761\u001b[0m  0.0932\n",
            "     60        4.7338  0.1048\n",
            "     61        \u001b[36m3.6632\u001b[0m  0.1678\n",
            "     62        \u001b[36m3.1204\u001b[0m  0.4861\n",
            "     63        \u001b[36m2.6147\u001b[0m  0.2074\n",
            "     64        3.2077  0.1009\n",
            "     65        \u001b[36m1.9797\u001b[0m  0.1106\n",
            "     66        2.8691  0.1113\n",
            "     67        2.3449  0.0907\n",
            "     68        \u001b[36m1.7517\u001b[0m  0.0987\n",
            "     69        1.8368  0.0967\n",
            "     70        \u001b[36m1.6321\u001b[0m  0.1159\n",
            "     71        \u001b[36m1.0974\u001b[0m  0.0981\n",
            "     72        1.3904  0.0905\n",
            "     73        1.6784  0.0905\n",
            "     74        \u001b[36m0.7344\u001b[0m  0.0907\n",
            "     75        1.5099  0.1048\n",
            "     76        1.7670  0.1031\n",
            "     77        1.2963  0.0957\n",
            "     78        1.3969  0.0953\n",
            "     79        1.0285  0.0979\n",
            "     80        0.8692  0.0885\n",
            "     81        \u001b[36m0.6661\u001b[0m  0.1025\n",
            "     82        0.7219  0.1121\n",
            "     83        2.1380  0.0933\n",
            "     84        0.6665  0.0959\n",
            "     85        1.0512  0.0998\n",
            "     86        0.7837  0.0868\n",
            "     87        0.9225  0.0912\n",
            "     88        1.0055  0.1153\n",
            "     89        \u001b[36m0.6650\u001b[0m  0.1074\n",
            "     90        \u001b[36m0.5909\u001b[0m  0.0898\n",
            "     91        0.7222  0.0960\n",
            "     92        1.0475  0.0908\n",
            "     93        \u001b[36m0.5854\u001b[0m  0.0910\n",
            "     94        0.6816  0.1042\n",
            "     95        0.8001  0.1022\n",
            "     96        0.8792  0.0940\n",
            "     97        1.0968  0.0886\n",
            "     98        1.0822  0.0894\n",
            "     99        0.6771  0.0875\n",
            "    100        0.6372  0.0940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1TdQyUmrNUs",
        "outputId": "e69fcba8-05f5-4b93-a6ae-b6fb9aa1e8ed"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.87719298, 0.61403509, 0.87719298, 0.8245614 , 0.78947368,\n",
              "       0.61403509, 0.63157895, 0.78947368, 0.8245614 , 0.66071429])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_2.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKGWTLK3sRgc",
        "outputId": "a20b79dd-7862-4951-d256-ef63d4caae9b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7502819548872182"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_2.std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAkR3egRsTyl",
        "outputId": "0ac31e84-62a9-4bc1-af9c-bce9e6d2a5c6"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10274184302813122"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sPLdraRNsY2s"
      },
      "execution_count": 72,
      "outputs": []
    }
  ]
}